{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d299959-9d21-4b65-9775-a2e9845ffd5c",
   "metadata": {},
   "source": [
    "### WGAN与原始版本GAN和DCGAN差异较大，请仔细阅读文档并补充完整下面的代码。在需要补充的部分已经标注#TODO并附上相应的内容提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46231246-6adc-471e-a262-d9c6d0d3a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter  # TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df73c15-d470-4588-a9ea-a14b3d91ae4d",
   "metadata": {},
   "source": [
    "#### 根据文档和提示，补充完整WGAN的生成器Generator和判别器Discriminator代码：\n",
    "注意：\n",
    "1. WGAN 生成器的设计与 DCGAN 类似，但会使用 Tanh 激活函数将图像的像素值限制在 [-1, 1] 的范围内。\n",
    "2. 在 WGAN 中，判别器输出的是一个实数，而不是概率，因此不使用 sigmoid 激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231ecf9e-81d9-48b2-9d9c-1924ee0a6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== 生成器（Generator） ===============================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 1. 输入层：将 100 维随机噪声从input_dim投影到 32x32（1024 维）\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)   # 线性变换fc1，将输入噪声扩展到 1024 维\n",
    "\n",
    "        self.br1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024),  # 批归一化，加速训练并稳定收敛\n",
    "            nn.ReLU(inplace=True)   # ReLU 激活函数，引入非线性\n",
    "        )\n",
    "\n",
    "        # 2. 第二层：将 1024 维数据映射到 128 * 7 * 7 维\n",
    "        self.fc2 = nn.Linear(1024, 128 * 7 * 7)   # 线性变换，将数据变换为适合卷积层的维数大小\n",
    "\n",
    "        self.br2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(128 * 7 * 7),  # 批归一化\n",
    "            nn.ReLU(inplace=True)   # ReLU 激活函数\n",
    "        )\n",
    "\n",
    "        # 3. 反卷积层 1：上采样，输出 64 通道的 14×14 特征图\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 7x7 -> 14x14\n",
    "            nn.BatchNorm2d(64),  # 归一化，稳定训练\n",
    "            nn.ReLU(inplace=True)   # ReLU 激活函数\n",
    "        )\n",
    "\n",
    "        # 4. 反卷积层 2：输出 1 通道的 28×28 图像\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),  # 14x14 -> 28x28\n",
    "            nn.Tanh()    # WGAN 需要使用 Tanh 激活函数，将输出范围限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.br1(self.fc1(x))  # 通过全连接层，进行 BatchNorm 和 ReLU 激活\n",
    "        x = self.br2(self.fc2(x))  # 继续通过全连接层，进行 BatchNorm 和 ReLU 激活\n",
    "        x = x.reshape(-1, 128, 7, 7)  # 变形为适合卷积输入的形状 (batch, 128, 7, 7)\n",
    "        x = self.conv1(x)  # 反卷积：上采样到 14x14\n",
    "        output = self.conv2(x)  # 反卷积：上采样到 28x28\n",
    "        return output  # 返回生成的图像\n",
    "\n",
    "# =============================== 判别器（Discriminator） ===============================\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 1. 第一层：输入 1 通道的 28x28 图像，输出 32 通道的特征图，然后通过MaxPool2d降采样\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),  # 5x5 卷积核，步长为1\n",
    "            nn.LeakyReLU(negative_slope=0.1, inplace=True)   # LeakyReLU，negative_slope参数设置为0.1\n",
    "        )\n",
    "        self.pl1 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # 2. 第二层：输入 32 通道，输出 64 通道特征, 然后通过MaxPool2d降采样\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),  # 5x5 卷积核，步长为1\n",
    "            nn.LeakyReLU(negative_slope=0.1, inplace=True)  # LeakyReLU 激活函数，negative_slope参数设置为0.1\n",
    "        )\n",
    "        self.pl2 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "        # 3. 全连接层 1：将 64x4x4 维特征图转换成 1024 维向量\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 1024),  # 线性变换，将 64x7x7 映射到 1024 维\n",
    "            nn.LeakyReLU(negative_slope=0.1, inplace=True)   # LeakyReLU 激活函数\n",
    "        )\n",
    "\n",
    "        # 4. 全连接层 2：最终输出\n",
    "        self.fc2 = nn.Linear(1024, 1) # 输出一个标量作为判别结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pl1(self.conv1(x))  # 第一层卷积，降维\n",
    "        x = self.pl2(self.conv2(x))  # 第二层卷积，降维\n",
    "        x = x.view(x.shape[0], -1)  # 展平成向量\n",
    "        x = self.fc1(x)  # 通过全连接层\n",
    "        output = self.fc2(x)  # 通过最后一层全连接层，输出标量\n",
    "        return output  # 返回判别结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfad47-ba00-4cad-bf4d-d0782d3d0d80",
   "metadata": {},
   "source": [
    "#### 补充完整主函数。\n",
    "注意：\n",
    "1. 传统的GAN通常使用[0, 1]范围的图像作为输入，但WGAN要求图像的像素值在 [-1, 1] 范围内。此时，输入图像的像素值需要做归一化，使用 (0.5,) 作为均值 (0.5) 和 (0.5,) 作为标准差，确保每个像素的值都被调整到 [-1, 1] 之间。\n",
    "2. 与传统的GAN使用Adam优化器不同，WGAN推荐使用RMSprop优化器。\n",
    "3. 在WGAN中，通常需要在每次生成器训练之前，先训练判别器多次。这种策略有助于使判别器的训练更加稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "053bc8c0-fc04-45f0-9a44-0213f61b9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== 主函数 ===============================\n",
    "def main():\n",
    "    # 设备配置\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 设定超参数\n",
    "    input_dim = 100\n",
    "    batch_size = 128\n",
    "    num_epoch = 30\n",
    "    clip_value = 0.01   # 判别器权重裁剪范围，确保满足 Lipschitz 条件\n",
    "\n",
    "    # 加载 MNIST 数据集\n",
    "    train_dataset = datasets.MNIST(root=\"./data/\", train=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]), download=True)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 创建生成器G和判别器D，并移动到 GPU（如果可用）\n",
    "    G = Generator(input_dim).to(device)\n",
    "    D = Discriminator().to(device)\n",
    "    \n",
    "    # 定义优化器optim_G和optim_D：使用RMSprop，学习率设置为0.00005\n",
    "    optim_G = torch.optim.RMSprop(G.parameters(), lr=0.00005)\n",
    "    optim_D = torch.optim.RMSprop(D.parameters(), lr=0.00005)\n",
    "\n",
    "    # 初始化 TensorBoard\n",
    "    writer = SummaryWriter(log_dir='./logs/experiment_wgan')\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(num_epoch):\n",
    "        total_loss_D, total_loss_G = 0, 0\n",
    "        for i, (real_images, _) in enumerate(train_loader):\n",
    "            # 判别器训练5次，然后训练生成器1次。提示：for循环，记得修改total_loss_D和total_loss_G的值\n",
    "            # TODO  # 判别器训练 5 次\n",
    "            real_images = real_images.to(device)\n",
    "            D.zero_grad()\n",
    "            for _ in range(5):  # 训练判别器 5 次\n",
    "                loss_D = train_discriminator(real_images, D, G, optim_D, clip_value, batch_size, input_dim, device)\n",
    "                total_loss_D += loss_D\n",
    "\n",
    "            # TODO  # 生成器训练 1 次\n",
    "            G.zero_grad()\n",
    "            loss_G = train_generator(D, G, optim_G, batch_size, input_dim, device)\n",
    "            total_loss_G += loss_G\n",
    "\n",
    "            # 每 100 步打印一次损失\n",
    "            if (i + 1) % 100 == 0 or (i + 1) == len(train_loader):\n",
    "                print(f'Epoch {epoch:02d} | Step {i + 1:04d} / {len(train_loader)} | Loss_D {total_loss_D / (i + 1):.4f} | Loss_G {total_loss_G / (i + 1):.4f}')\n",
    "\n",
    "        # 记录损失到 TensorBoard\n",
    "        writer.add_scalar('WGAN/Loss/Discriminator', total_loss_D / len(train_loader), epoch)\n",
    "        writer.add_scalar('WGAN/Loss/Generator', total_loss_G / len(train_loader), epoch)\n",
    "\n",
    "        # 生成并保存示例图像\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(64, input_dim, device=device)\n",
    "            fake_images = G(noise)\n",
    "\n",
    "            # 记录生成的图像到 TensorBoard\n",
    "            img_grid = torchvision.utils.make_grid(fake_images, normalize=True)\n",
    "            writer.add_image('Generated Images', img_grid, epoch)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883ad9f-7b8d-4cf8-a622-99936a3abc82",
   "metadata": {},
   "source": [
    "#### 根据文档中描述的GAN的损失函数和二元交叉熵损失相关内容，补充完善Discriminator和Generator的训练过程：\n",
    "注意：\n",
    "1. 判别器需要进行权重裁剪操作；\n",
    "2. 生成器和判别器的损失函数与GAN和DCGAN不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f748fae-5147-4a63-8dc7-e6da56479a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== 训练判别器 ===============================\n",
    "def train_discriminator(real_images, D, G, optim_D, clip_value, batch_size, input_dim, device):\n",
    "    '''训练判别器'''\n",
    "    real_images = real_images.to(device)\n",
    "    real_output = D(real_images)\n",
    "\n",
    "    noise = torch.randn(batch_size, input_dim, device=device)\n",
    "    fake_images = G(noise).detach()\n",
    "    fake_output = D(fake_images)\n",
    "\n",
    "    loss_D = -(torch.mean(real_output) - torch.mean(fake_output))  # 计算判别器的损失函数\n",
    "\n",
    "    optim_D.zero_grad()\n",
    "    loss_D.backward()\n",
    "    optim_D.step()\n",
    "\n",
    "    # 对判别器参数进行裁剪\n",
    "    for p in D.parameters():\n",
    "        p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "    return loss_D.item()\n",
    "\n",
    "# =============================== 训练生成器 ===============================\n",
    "def train_generator(D, G, optim_G, batch_size, input_dim, device):\n",
    "    '''训练生成器'''\n",
    "    noise = torch.randn(batch_size, input_dim, device=device)\n",
    "    fake_images = G(noise)\n",
    "    fake_output = D(fake_images)\n",
    "\n",
    "    loss_G = -torch.mean(fake_output)  # 计算生成器的损失函数\n",
    "\n",
    "    optim_G.zero_grad()\n",
    "    loss_G.backward()\n",
    "    optim_G.step()\n",
    "\n",
    "    return loss_G.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aa0f1be-01e8-4ff6-8bf3-5008ce586f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Step 0100 / 469 | Loss_D -64.6738 | Loss_G 13.5033\n",
      "Epoch 00 | Step 0200 / 469 | Loss_D -68.5949 | Loss_G -14.1268\n",
      "Epoch 00 | Step 0300 / 469 | Loss_D -56.9703 | Loss_G -38.5017\n",
      "Epoch 00 | Step 0400 / 469 | Loss_D -44.9736 | Loss_G -43.3317\n",
      "Epoch 00 | Step 0469 / 469 | Loss_D -39.4251 | Loss_G -43.7726\n",
      "Epoch 01 | Step 0100 / 469 | Loss_D -6.1715 | Loss_G -41.9530\n",
      "Epoch 01 | Step 0200 / 469 | Loss_D -5.3883 | Loss_G -35.7723\n",
      "Epoch 01 | Step 0300 / 469 | Loss_D -4.6729 | Loss_G -30.8926\n",
      "Epoch 01 | Step 0400 / 469 | Loss_D -4.1898 | Loss_G -27.7320\n",
      "Epoch 01 | Step 0469 / 469 | Loss_D -3.8991 | Loss_G -25.6960\n",
      "Epoch 02 | Step 0100 / 469 | Loss_D -1.8247 | Loss_G -13.4401\n",
      "Epoch 02 | Step 0200 / 469 | Loss_D -1.6362 | Loss_G -13.2595\n",
      "Epoch 02 | Step 0300 / 469 | Loss_D -1.5032 | Loss_G -12.9272\n",
      "Epoch 02 | Step 0400 / 469 | Loss_D -1.4129 | Loss_G -12.5144\n",
      "Epoch 02 | Step 0469 / 469 | Loss_D -1.3726 | Loss_G -12.1221\n",
      "Epoch 03 | Step 0100 / 469 | Loss_D -1.2236 | Loss_G -8.3419\n",
      "Epoch 03 | Step 0200 / 469 | Loss_D -1.2219 | Loss_G -7.9565\n",
      "Epoch 03 | Step 0300 / 469 | Loss_D -1.1928 | Loss_G -7.7056\n",
      "Epoch 03 | Step 0400 / 469 | Loss_D -1.1609 | Loss_G -7.6650\n",
      "Epoch 03 | Step 0469 / 469 | Loss_D -1.1402 | Loss_G -7.6252\n",
      "Epoch 04 | Step 0100 / 469 | Loss_D -0.9537 | Loss_G -7.7919\n",
      "Epoch 04 | Step 0200 / 469 | Loss_D -0.9220 | Loss_G -7.6844\n",
      "Epoch 04 | Step 0300 / 469 | Loss_D -0.8891 | Loss_G -7.5784\n",
      "Epoch 04 | Step 0400 / 469 | Loss_D -0.8590 | Loss_G -7.5288\n",
      "Epoch 04 | Step 0469 / 469 | Loss_D -0.8418 | Loss_G -7.4585\n",
      "Epoch 05 | Step 0100 / 469 | Loss_D -0.7089 | Loss_G -6.8225\n",
      "Epoch 05 | Step 0200 / 469 | Loss_D -0.6884 | Loss_G -6.9193\n",
      "Epoch 05 | Step 0300 / 469 | Loss_D -0.6771 | Loss_G -6.8134\n",
      "Epoch 05 | Step 0400 / 469 | Loss_D -0.6674 | Loss_G -6.6880\n",
      "Epoch 05 | Step 0469 / 469 | Loss_D -0.6602 | Loss_G -6.6312\n",
      "Epoch 06 | Step 0100 / 469 | Loss_D -0.6084 | Loss_G -5.8277\n",
      "Epoch 06 | Step 0200 / 469 | Loss_D -0.6021 | Loss_G -5.6824\n",
      "Epoch 06 | Step 0300 / 469 | Loss_D -0.5938 | Loss_G -5.5928\n",
      "Epoch 06 | Step 0400 / 469 | Loss_D -0.5843 | Loss_G -5.5461\n",
      "Epoch 06 | Step 0469 / 469 | Loss_D -0.5792 | Loss_G -5.5251\n",
      "Epoch 07 | Step 0100 / 469 | Loss_D -0.5368 | Loss_G -5.2246\n",
      "Epoch 07 | Step 0200 / 469 | Loss_D -0.5332 | Loss_G -5.3106\n",
      "Epoch 07 | Step 0300 / 469 | Loss_D -0.5356 | Loss_G -5.2581\n",
      "Epoch 07 | Step 0400 / 469 | Loss_D -0.5376 | Loss_G -5.1800\n",
      "Epoch 07 | Step 0469 / 469 | Loss_D -0.5380 | Loss_G -5.1355\n",
      "Epoch 08 | Step 0100 / 469 | Loss_D -0.5201 | Loss_G -4.8415\n",
      "Epoch 08 | Step 0200 / 469 | Loss_D -0.5189 | Loss_G -4.8297\n",
      "Epoch 08 | Step 0300 / 469 | Loss_D -0.5152 | Loss_G -4.7983\n",
      "Epoch 08 | Step 0400 / 469 | Loss_D -0.5126 | Loss_G -4.7946\n",
      "Epoch 08 | Step 0469 / 469 | Loss_D -0.5095 | Loss_G -4.7678\n",
      "Epoch 09 | Step 0100 / 469 | Loss_D -0.6358 | Loss_G -3.7126\n",
      "Epoch 09 | Step 0200 / 469 | Loss_D -0.7207 | Loss_G -3.8241\n",
      "Epoch 09 | Step 0300 / 469 | Loss_D -0.7536 | Loss_G -3.8589\n",
      "Epoch 09 | Step 0400 / 469 | Loss_D -0.7676 | Loss_G -3.8814\n",
      "Epoch 09 | Step 0469 / 469 | Loss_D -0.7738 | Loss_G -3.8411\n",
      "Epoch 10 | Step 0100 / 469 | Loss_D -0.7963 | Loss_G -3.5493\n",
      "Epoch 10 | Step 0200 / 469 | Loss_D -0.7956 | Loss_G -3.5155\n",
      "Epoch 10 | Step 0300 / 469 | Loss_D -0.7880 | Loss_G -3.5662\n",
      "Epoch 10 | Step 0400 / 469 | Loss_D -0.7844 | Loss_G -3.5329\n",
      "Epoch 10 | Step 0469 / 469 | Loss_D -0.7797 | Loss_G -3.5296\n",
      "Epoch 11 | Step 0100 / 469 | Loss_D -0.7515 | Loss_G -3.3435\n",
      "Epoch 11 | Step 0200 / 469 | Loss_D -0.7506 | Loss_G -3.4448\n",
      "Epoch 11 | Step 0300 / 469 | Loss_D -0.7541 | Loss_G -3.3862\n",
      "Epoch 11 | Step 0400 / 469 | Loss_D -0.7488 | Loss_G -3.3642\n",
      "Epoch 11 | Step 0469 / 469 | Loss_D -0.7487 | Loss_G -3.3926\n",
      "Epoch 12 | Step 0100 / 469 | Loss_D -0.7367 | Loss_G -3.3181\n",
      "Epoch 12 | Step 0200 / 469 | Loss_D -0.7365 | Loss_G -3.2741\n",
      "Epoch 12 | Step 0300 / 469 | Loss_D -0.7340 | Loss_G -3.2965\n",
      "Epoch 12 | Step 0400 / 469 | Loss_D -0.7377 | Loss_G -3.2689\n",
      "Epoch 12 | Step 0469 / 469 | Loss_D -0.7356 | Loss_G -3.1129\n",
      "Epoch 13 | Step 0100 / 469 | Loss_D -0.7170 | Loss_G -3.0293\n",
      "Epoch 13 | Step 0200 / 469 | Loss_D -0.7151 | Loss_G -2.9806\n",
      "Epoch 13 | Step 0300 / 469 | Loss_D -0.7176 | Loss_G -2.9284\n",
      "Epoch 13 | Step 0400 / 469 | Loss_D -0.7098 | Loss_G -2.8688\n",
      "Epoch 13 | Step 0469 / 469 | Loss_D -0.7093 | Loss_G -2.9411\n",
      "Epoch 14 | Step 0100 / 469 | Loss_D -0.6883 | Loss_G -2.6305\n",
      "Epoch 14 | Step 0200 / 469 | Loss_D -0.6851 | Loss_G -2.7549\n",
      "Epoch 14 | Step 0300 / 469 | Loss_D -0.6897 | Loss_G -2.6776\n",
      "Epoch 14 | Step 0400 / 469 | Loss_D -0.6858 | Loss_G -2.6715\n",
      "Epoch 14 | Step 0469 / 469 | Loss_D -0.6832 | Loss_G -2.6976\n",
      "Epoch 15 | Step 0100 / 469 | Loss_D -0.6592 | Loss_G -2.0945\n",
      "Epoch 15 | Step 0200 / 469 | Loss_D -0.6606 | Loss_G -2.2830\n",
      "Epoch 15 | Step 0300 / 469 | Loss_D -0.6559 | Loss_G -2.3914\n",
      "Epoch 15 | Step 0400 / 469 | Loss_D -0.6556 | Loss_G -2.3381\n",
      "Epoch 15 | Step 0469 / 469 | Loss_D -0.6535 | Loss_G -2.3217\n",
      "Epoch 16 | Step 0100 / 469 | Loss_D -0.6544 | Loss_G -2.3882\n",
      "Epoch 16 | Step 0200 / 469 | Loss_D -0.6488 | Loss_G -2.4221\n",
      "Epoch 16 | Step 0300 / 469 | Loss_D -0.6486 | Loss_G -2.4610\n",
      "Epoch 16 | Step 0400 / 469 | Loss_D -0.6441 | Loss_G -2.3972\n",
      "Epoch 16 | Step 0469 / 469 | Loss_D -0.6419 | Loss_G -2.3094\n",
      "Epoch 17 | Step 0100 / 469 | Loss_D -0.6185 | Loss_G -2.1528\n",
      "Epoch 17 | Step 0200 / 469 | Loss_D -0.6248 | Loss_G -2.2170\n",
      "Epoch 17 | Step 0300 / 469 | Loss_D -0.6185 | Loss_G -2.0677\n",
      "Epoch 17 | Step 0400 / 469 | Loss_D -0.6151 | Loss_G -2.0666\n",
      "Epoch 17 | Step 0469 / 469 | Loss_D -0.6149 | Loss_G -2.0574\n",
      "Epoch 18 | Step 0100 / 469 | Loss_D -0.6141 | Loss_G -2.2455\n",
      "Epoch 18 | Step 0200 / 469 | Loss_D -0.6169 | Loss_G -1.9182\n",
      "Epoch 18 | Step 0300 / 469 | Loss_D -0.6154 | Loss_G -1.8276\n",
      "Epoch 18 | Step 0400 / 469 | Loss_D -0.6115 | Loss_G -1.8421\n",
      "Epoch 18 | Step 0469 / 469 | Loss_D -0.6056 | Loss_G -1.8465\n",
      "Epoch 19 | Step 0100 / 469 | Loss_D -0.6035 | Loss_G -1.6506\n",
      "Epoch 19 | Step 0200 / 469 | Loss_D -0.6044 | Loss_G -1.6423\n",
      "Epoch 19 | Step 0300 / 469 | Loss_D -0.5975 | Loss_G -1.6891\n",
      "Epoch 19 | Step 0400 / 469 | Loss_D -0.5873 | Loss_G -1.7133\n",
      "Epoch 19 | Step 0469 / 469 | Loss_D -0.5848 | Loss_G -1.7246\n",
      "Epoch 20 | Step 0100 / 469 | Loss_D -0.5645 | Loss_G -1.6819\n",
      "Epoch 20 | Step 0200 / 469 | Loss_D -0.5711 | Loss_G -1.5709\n",
      "Epoch 20 | Step 0300 / 469 | Loss_D -0.5731 | Loss_G -1.5714\n",
      "Epoch 20 | Step 0400 / 469 | Loss_D -0.5692 | Loss_G -1.5583\n",
      "Epoch 20 | Step 0469 / 469 | Loss_D -0.5694 | Loss_G -1.5380\n",
      "Epoch 21 | Step 0100 / 469 | Loss_D -0.5507 | Loss_G -1.4850\n",
      "Epoch 21 | Step 0200 / 469 | Loss_D -0.5541 | Loss_G -1.3346\n",
      "Epoch 21 | Step 0300 / 469 | Loss_D -0.5508 | Loss_G -1.2780\n",
      "Epoch 21 | Step 0400 / 469 | Loss_D -0.5516 | Loss_G -1.3097\n",
      "Epoch 21 | Step 0469 / 469 | Loss_D -0.5528 | Loss_G -1.3897\n",
      "Epoch 22 | Step 0100 / 469 | Loss_D -0.5360 | Loss_G -1.2820\n",
      "Epoch 22 | Step 0200 / 469 | Loss_D -0.5491 | Loss_G -1.4153\n",
      "Epoch 22 | Step 0300 / 469 | Loss_D -0.5395 | Loss_G -1.2767\n",
      "Epoch 22 | Step 0400 / 469 | Loss_D -0.5408 | Loss_G -1.2314\n",
      "Epoch 22 | Step 0469 / 469 | Loss_D -0.5386 | Loss_G -1.2535\n",
      "Epoch 23 | Step 0100 / 469 | Loss_D -0.5376 | Loss_G -1.1935\n",
      "Epoch 23 | Step 0200 / 469 | Loss_D -0.5306 | Loss_G -1.3215\n",
      "Epoch 23 | Step 0300 / 469 | Loss_D -0.5316 | Loss_G -1.3384\n",
      "Epoch 23 | Step 0400 / 469 | Loss_D -0.5283 | Loss_G -1.4121\n",
      "Epoch 23 | Step 0469 / 469 | Loss_D -0.5277 | Loss_G -1.3629\n",
      "Epoch 24 | Step 0100 / 469 | Loss_D -0.5208 | Loss_G -1.4620\n",
      "Epoch 24 | Step 0200 / 469 | Loss_D -0.5217 | Loss_G -1.5496\n",
      "Epoch 24 | Step 0300 / 469 | Loss_D -0.5231 | Loss_G -1.6396\n",
      "Epoch 24 | Step 0400 / 469 | Loss_D -0.5157 | Loss_G -1.3836\n",
      "Epoch 24 | Step 0469 / 469 | Loss_D -0.5156 | Loss_G -1.4155\n",
      "Epoch 25 | Step 0100 / 469 | Loss_D -0.5437 | Loss_G -1.5383\n",
      "Epoch 25 | Step 0200 / 469 | Loss_D -0.5134 | Loss_G -1.4059\n",
      "Epoch 25 | Step 0300 / 469 | Loss_D -0.5082 | Loss_G -1.4897\n",
      "Epoch 25 | Step 0400 / 469 | Loss_D -0.5098 | Loss_G -1.4160\n",
      "Epoch 25 | Step 0469 / 469 | Loss_D -0.5144 | Loss_G -1.4555\n",
      "Epoch 26 | Step 0100 / 469 | Loss_D -0.5042 | Loss_G -1.9173\n",
      "Epoch 26 | Step 0200 / 469 | Loss_D -0.5063 | Loss_G -1.5901\n",
      "Epoch 26 | Step 0300 / 469 | Loss_D -0.5058 | Loss_G -1.6931\n",
      "Epoch 26 | Step 0400 / 469 | Loss_D -0.5039 | Loss_G -1.6670\n",
      "Epoch 26 | Step 0469 / 469 | Loss_D -0.5067 | Loss_G -1.7080\n",
      "Epoch 27 | Step 0100 / 469 | Loss_D -0.4874 | Loss_G -1.4905\n",
      "Epoch 27 | Step 0200 / 469 | Loss_D -0.4846 | Loss_G -1.5736\n",
      "Epoch 27 | Step 0300 / 469 | Loss_D -0.4813 | Loss_G -1.3768\n",
      "Epoch 27 | Step 0400 / 469 | Loss_D -0.4814 | Loss_G -1.4451\n",
      "Epoch 27 | Step 0469 / 469 | Loss_D -0.4875 | Loss_G -1.3137\n",
      "Epoch 28 | Step 0100 / 469 | Loss_D -0.4799 | Loss_G -1.3685\n",
      "Epoch 28 | Step 0200 / 469 | Loss_D -0.4799 | Loss_G -1.2503\n",
      "Epoch 28 | Step 0300 / 469 | Loss_D -0.4841 | Loss_G -1.2474\n",
      "Epoch 28 | Step 0400 / 469 | Loss_D -0.4829 | Loss_G -1.2645\n",
      "Epoch 28 | Step 0469 / 469 | Loss_D -0.4847 | Loss_G -1.2224\n",
      "Epoch 29 | Step 0100 / 469 | Loss_D -0.4973 | Loss_G -1.2112\n",
      "Epoch 29 | Step 0200 / 469 | Loss_D -0.4805 | Loss_G -1.3272\n",
      "Epoch 29 | Step 0300 / 469 | Loss_D -0.4793 | Loss_G -1.4357\n",
      "Epoch 29 | Step 0400 / 469 | Loss_D -0.4801 | Loss_G -1.3945\n",
      "Epoch 29 | Step 0469 / 469 | Loss_D -0.4775 | Loss_G -1.3827\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
