{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6376419e",
   "metadata": {},
   "source": [
    "# å®éªŒä»»åŠ¡äºŒ: RNNã€LSTMå’ŒGRUæ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n",
    "\n",
    "## **1. æ–‡æœ¬é¢„å¤„ç†**\n",
    "æ–‡æœ¬é¢„å¤„ç†ç®€ä»‹\n",
    "    æ–‡æœ¬é¢„å¤„ç†æ˜¯åœ¨æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ä¸­ï¼Œå¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œæ¸…ç†ã€è½¬æ¢å’Œæ ¼å¼åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«æ¨¡å‹ç†è§£å’Œå¤„ç†çš„è¿‡ç¨‹ã€‚\n",
    "\n",
    "é¢„å¤„ç†çš„å¿…è¦æ€§\n",
    "    åŸå§‹æ–‡æœ¬å¯èƒ½åŒ…å«å™ªå£°ï¼Œä¸”æ–‡æœ¬é•¿åº¦ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ‰¹é‡è®­ç»ƒæ—¶éœ€è¦å¡«å……\n",
    "\n",
    "AG News æ•°æ®é›†ç®€ä»‹\n",
    "\n",
    "    AG News æ•°æ®é›†æ¥æºäº AG's corpus of news articlesï¼Œæ˜¯ä¸€ä¸ªå¤§å‹çš„æ–°é—»æ•°æ®é›†ï¼Œç”± Antonio Gulli ä»å¤šä¸ªæ–°é—»ç½‘ç«™æ”¶é›†æ•´ç†ã€‚\n",
    "    AG News æ•°æ®é›†åŒ…å« 4 ç±»æ–°é—»ï¼Œæ¯ç±» 30,000 æ¡è®­ç»ƒæ•°æ®ï¼Œå…± 120,000 æ¡è®­ç»ƒæ ·æœ¬ å’Œ 7,600 æ¡æµ‹è¯•æ ·æœ¬ã€‚\n",
    "\n",
    "é¦–å…ˆå¯¼å…¥æ‰€éœ€æ¨¡å—ï¼š\n",
    "\n",
    "å¯èƒ½éœ€è¦å®‰è£…datasetsåŒ…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870a68277a4854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17399ab3db54117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c858707e89b9c13",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä»AG News æ•°æ®é›†ä¸­åŠ è½½æ–‡æœ¬ã€‚ è¿™æ˜¯ä¸€ä¸ªè¾ƒå°çš„è¯­æ–™åº“ï¼Œæœ‰150000å¤šä¸ªå•è¯ï¼Œä½†è¶³å¤Ÿæˆ‘ä»¬å°è¯•ç‰›åˆ€.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf5d0a68732b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/ag_news\"\n",
    "dataset = load_from_disk(data_path)\n",
    "\n",
    "# æå–æ‰€æœ‰æ–‡æœ¬æ•°æ®\n",
    "train_text = [item['text'] for item in dataset['train']]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab1a668ad3d165",
   "metadata": {},
   "source": [
    "è¯å…ƒåŒ–\n",
    "ä¸‹é¢çš„tokenizeå‡½æ•°å°†æ–‡æœ¬è¡Œåˆ—è¡¨ï¼ˆlinesï¼‰ä½œä¸ºè¾“å…¥ï¼Œ åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼ˆå¦‚ä¸€æ¡æ–‡æœ¬è¡Œï¼‰ã€‚ æ¯ä¸ªæ–‡æœ¬åºåˆ—åˆè¢«æ‹†åˆ†æˆä¸€ä¸ªè¯å…ƒåˆ—è¡¨ï¼Œè¯å…ƒï¼ˆtokenï¼‰æ˜¯æ–‡æœ¬çš„åŸºæœ¬å•ä½ã€‚ æœ€åï¼Œè¿”å›ä¸€ä¸ªç”±è¯å…ƒåˆ—è¡¨ç»„æˆçš„åˆ—è¡¨ï¼Œå…¶ä¸­çš„æ¯ä¸ªè¯å…ƒéƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆstringï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2748b26c2e6c70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ split è¿›è¡Œåˆ†è¯\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# ç”Ÿæˆè¯æ±‡è¡¨\n",
    "counter = Counter()\n",
    "for text in train_text:\n",
    "    counter.update(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7962eff64eb92",
   "metadata": {},
   "source": [
    "è¯å…ƒçš„ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œæ¨¡å‹éœ€è¦çš„è¾“å…¥æ˜¯æ•°å­—ï¼Œå› æ­¤è¿™ç§ç±»å‹ä¸æ–¹ä¾¿æ¨¡å‹ä½¿ç”¨ã€‚ ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå­—å…¸ï¼Œé€šå¸¸ä¹Ÿå«åšè¯è¡¨ï¼ˆvocabularyï¼‰ï¼Œ ç”¨æ¥å°†å­—ç¬¦ä¸²ç±»å‹çš„è¯å…ƒæ˜ å°„åˆ°ä»0å¼€å§‹çš„æ•°å­—ç´¢å¼•ä¸­ã€‚\n",
    "é¦–å…ˆï¼Œå®šä¹‰ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ <unk> ä»£è¡¨æœªçŸ¥è¯ï¼Œ<pad> ç”¨äºåºåˆ—å¡«å……ï¼Œ<bos>è¡¨ç¤ºåºåˆ—å¼€å§‹ï¼Œ<eos>è¡¨ç¤ºåºåˆ—ç»“æŸï¼‰ã€‚ç„¶åï¼Œä» Counter ç»Ÿè®¡çš„å•è¯é¢‘ç‡åˆ—è¡¨ä¸­æå–æ‰€æœ‰å•è¯ï¼Œå¹¶æŒ‰é¢‘ç‡æ’åºï¼Œå°†å…¶æ·»åŠ åˆ°è¯æ±‡è¡¨ä¸­ã€‚æœ€åï¼Œä½¿ç”¨ enumerate ä¸ºæ¯ä¸ªå•è¯åˆ†é…å”¯ä¸€ç´¢å¼•ï¼Œåˆ›å»ºä¸€ä¸ª word-to-index æ˜ å°„ï¼Œæ–¹ä¾¿å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼åºåˆ—ä¾›æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4beb7d758643a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆè¯æ±‡è¡¨ï¼ŒåŒ…å«ç‰¹æ®Š token\n",
    "special_tokens = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "vocab = special_tokens + [word for word, _ in counter.most_common()]\n",
    "vocab_dict = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a0504ff359aa7",
   "metadata": {},
   "source": [
    "\n",
    "æ‰“å°è¯æ±‡è¡¨å¤§å°ï¼Œå‰10ä¸ªé«˜é¢‘è¯å…ƒåŠå…¶ç´¢å¼•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161c78fff5d25175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯æ±‡è¡¨å¤§å°: 158737\n",
      "å‰ 10 ä¸ªæœ€å¸¸è§çš„å•è¯åŠå…¶ç´¢å¼•:\n",
      "å•è¯: the, ç´¢å¼•: 4\n",
      "å•è¯: to, ç´¢å¼•: 5\n",
      "å•è¯: a, ç´¢å¼•: 6\n",
      "å•è¯: of, ç´¢å¼•: 7\n",
      "å•è¯: in, ç´¢å¼•: 8\n",
      "å•è¯: and, ç´¢å¼•: 9\n",
      "å•è¯: on, ç´¢å¼•: 10\n",
      "å•è¯: for, ç´¢å¼•: 11\n",
      "å•è¯: -, ç´¢å¼•: 12\n",
      "å•è¯: #39;s, ç´¢å¼•: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"è¯æ±‡è¡¨å¤§å°:\", len(vocab_dict))\n",
    "print(\"å‰ 10 ä¸ªæœ€å¸¸è§çš„å•è¯åŠå…¶ç´¢å¼•:\")\n",
    "#TODO:æ‰“å°å‰10ä¸ªé«˜é¢‘è¯å…ƒåŠå…¶ç´¢å¼•\n",
    "for word, _ in counter.most_common(10):\n",
    "    print(f\"å•è¯: {word}, ç´¢å¼•: {vocab_dict.get(word, '<unk>')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734720ce2043c4",
   "metadata": {},
   "source": [
    "\n",
    "    æ€è€ƒé¢˜1ï¼šåœ¨æ–‡æœ¬å¤„ç†ä¸­ï¼Œä¸ºä»€ä¹ˆéœ€è¦å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼ˆTokenizationï¼‰ï¼Ÿ\n",
    "\n",
    "    æ€è€ƒé¢˜2ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ä½¿ç”¨å•è¯è€Œéœ€è¦å°†å…¶è½¬æ¢ä¸ºç´¢å¼•ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc14a970d1d30f",
   "metadata": {},
   "source": [
    "## **2. RNNæ–‡æœ¬ç”Ÿæˆå®éªŒ**\n",
    "\n",
    "\"RNNæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\"\n",
    "\n",
    "    ä½¿ç”¨RNNè¿›è¡Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡çš„æ ¸å¿ƒæ€æƒ³æ˜¯ æ ¹æ®å‰é¢çš„æ–‡æœ¬é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œç„¶åå°†é¢„æµ‹å‡ºçš„å•è¯ä½œä¸ºè¾“å…¥ï¼Œå¾ªç¯è¿­ä»£ç”Ÿæˆå®Œæ•´æ–‡æœ¬ã€‚æœ¬å®éªŒä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
    "\n",
    "\"RNNçš„å±€é™æ€§\"\n",
    "\n",
    "    RNNçš„å±€é™æ€§åœ¨äºéš¾ä»¥è®°ä½é•¿è·ç¦»ä¸Šä¸‹æ–‡ï¼Œå®¹æ˜“å¯¼è‡´ç”Ÿæˆå†…å®¹ç¼ºä¹è¿è´¯æ€§ï¼Œä¸”å¯èƒ½å‡ºç°é‡å¤æˆ–æ¨¡å¼åŒ–çš„æ–‡æœ¬ã€‚\n",
    "\n",
    "![ç¤ºä¾‹å›¾ç‰‡](pics/rnn.png)\n",
    "\n",
    "### å‰ç½®ä»£ç \n",
    "\n",
    "é¦–å…ˆå¯¼å…¥æ‰€éœ€æ¨¡å—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910d8e3c07f67072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5dfbf26750f226",
   "metadata": {},
   "source": [
    "è¯»å–æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8717c9e95d9e8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/ag_news\"\n",
    "dataset = load_from_disk(data_path)\n",
    "\n",
    "# æå–æ‰€æœ‰æ–‡æœ¬æ•°æ®\n",
    "train_text = [item['text'] for item in dataset['train']]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d041e69fb63a3",
   "metadata": {},
   "source": [
    "æ–‡æœ¬çš„é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3afddf94ced251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ä½¿ç”¨ split è¿›è¡Œåˆ†è¯\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# ç”Ÿæˆè¯æ±‡è¡¨\n",
    "counter = Counter()\n",
    "for text in train_text:\n",
    "    counter.update(tokenize(text))\n",
    "\n",
    "# ç”Ÿæˆè¯æ±‡è¡¨ï¼ŒåŒ…å«ç‰¹æ®Š token\n",
    "special_tokens = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "vocab = special_tokens + [word for word, _ in counter.most_common()]\n",
    "vocab_dict = {word: idx for idx, word in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d9b04dd0c2f9e",
   "metadata": {},
   "source": [
    "### è®­ç»ƒæ•°æ®ç”Ÿæˆ\n",
    "\n",
    "å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œå¹¶æŒ‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ã€ä¸‹ä¸€ä¸ªå•è¯ä½œä¸ºç›®æ ‡çš„æ–¹å¼æ„é€ è®­ç»ƒæ•°æ®ã€‚æœ€ç»ˆç”Ÿæˆ X_trainï¼ˆè¾“å…¥åºåˆ—ï¼‰å’Œ Y_trainï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰ï¼Œç”¨äº RNN è®­ç»ƒæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d33c3dfdd9212f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numericalize(text):\n",
    "    return torch.tensor([vocab_dict.get(word, vocab_dict[\"<unk>\"]) for word in tokenize(text)], dtype=torch.long)\n",
    "\n",
    "# ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆè¾“å…¥ 100 ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰\n",
    "def create_data(text_list, seq_len=100):\n",
    "    X, Y = [], []\n",
    "    for text in text_list:\n",
    "        token_ids = numericalize(text)\n",
    "        if len(token_ids) <= seq_len:\n",
    "            continue  # å¿½ç•¥è¿‡çŸ­çš„æ–‡æœ¬\n",
    "        for i in range(len(token_ids) - seq_len):\n",
    "            X.append(token_ids[i:i + seq_len])\n",
    "            Y.append(token_ids[i + seq_len])\n",
    "    return torch.stack(X), torch.tensor(Y)\n",
    "\n",
    "# ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "X_train, Y_train = create_data(train_text, seq_len=100)\n",
    "\n",
    "\n",
    "# åˆ›å»º DataLoader\n",
    "batch_size = 32\n",
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ecbe3b4987b16",
   "metadata": {},
   "source": [
    "\n",
    "    æ€è€ƒé¢˜3ï¼šå¦‚æœä¸æ‰“ä¹±è®­ç»ƒé›†ï¼Œä¼šå¯¹ç”Ÿæˆä»»åŠ¡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\n",
    "\n",
    "\n",
    "### RNN æ¨¡å‹æ„å»º\n",
    "\n",
    "å®ç°äº†ä¸€ä¸ªåŸºäº RNN çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147d6c280095cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
    "        super(RNNTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)#å°†è¾“å…¥çš„å•è¯ç´¢å¼•è½¬æ¢ä¸º embed_dim ç»´çš„å‘é‡ã€‚\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)#æ„å»ºä¸€ä¸ª RNN å±‚ï¼Œç”¨äºå¤„ç†åºåˆ—æ•°æ®ã€‚\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)#å°† RNN éšè—çŠ¶æ€ æ˜ å°„åˆ° è¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        #è¾“å…¥ x å½¢çŠ¶ï¼š(batch_size, seq_len)\n",
    "        #è¾“å‡º embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
    "        embedded = self.embedding(x)\n",
    "        #è¾“å…¥ embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
    "        #è¾“å‡º output å½¢çŠ¶ï¼š(batch_size, seq_len, hidden_dim)ï¼ˆæ‰€æœ‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
    "        #è¾“å‡º hidden å½¢çŠ¶ï¼š(num_layers, batch_size, hidden_dim)ï¼ˆæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        #åªå– æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ output[:, -1, :] ä½œä¸ºè¾“å…¥\n",
    "        #é€šè¿‡å…¨è¿æ¥å±‚ self.fc å°†éšè—çŠ¶æ€è½¬æ¢ä¸ºè¯æ±‡è¡¨å¤§å°çš„åˆ†å¸ƒï¼ˆç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼‰\n",
    "        #æœ€ç»ˆ output å½¢çŠ¶ï¼š(batch_size, vocab_size)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0eae4db36a71",
   "metadata": {},
   "source": [
    "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b124a501affec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "hidden_dim = 512\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = RNNTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9e86d4297477c",
   "metadata": {},
   "source": [
    "### RNN æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "RNN è®­ç»ƒè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3a4b5e87d77a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.45it/s, loss=12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 10.4269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.59it/s, loss=8.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 9.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.37it/s, loss=7.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 7.5999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.38it/s, loss=7.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 7.3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.45it/s, loss=8.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 7.3381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.19it/s, loss=6.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 7.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.61it/s, loss=8.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 7.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.65it/s, loss=11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 8.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.70it/s, loss=6.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 7.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.80it/s, loss=6.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 7.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.69it/s, loss=6.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 6.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.64it/s, loss=6.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 6.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.69it/s, loss=7.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 6.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.70it/s, loss=7.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 6.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.67it/s, loss=6.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 6.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.63it/s, loss=6.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 6.7652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.64it/s, loss=7.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 6.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.70it/s, loss=7.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 6.7555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.67it/s, loss=6.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 6.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.74it/s, loss=7.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 6.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    model.train()# å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")# ä½¿ç”¨ tqdm åˆ›å»ºè¿›åº¦æ¡\n",
    "        epoch_grad_norm = None\n",
    "\n",
    "        for X_batch, Y_batch in progress_bar:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)# å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
    "            optimizer.zero_grad()# æ¸…ç©ºä¸Šä¸€è½®çš„æ¢¯åº¦ï¼Œé˜²æ­¢æ¢¯åº¦ç´¯ç§¯\n",
    "\n",
    "            output, _ = model(X_batch)# å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ¨¡å‹è¾“å‡º\n",
    "            loss = criterion(output, Y_batch) # è®¡ç®—æŸå¤±å‡½æ•°å€¼\n",
    "            loss.backward()# åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦\n",
    "\n",
    "            optimizer.step() # æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "            total_loss += loss.item()# ç´¯åŠ å½“å‰ batch çš„æŸå¤±å€¼\n",
    "            progress_bar.set_postfix(loss=loss.item())# åœ¨è¿›åº¦æ¡ä¸Šæ˜¾ç¤ºå½“å‰ batch çš„æŸå¤±å€¼\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        # è®¡ç®—å¹¶è¾“å‡ºæœ¬è½®è®­ç»ƒçš„å¹³å‡æŸå¤±\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "train_model(model, train_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b633f9741598290",
   "metadata": {},
   "source": [
    "### RNN æ¨¡å‹æµ‹è¯•\n",
    "\n",
    "RNN ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97bbe30b05eb568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      "\n",
      "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
      "\n",
      "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. and lion's is mindfulness all added to targeted the for his send ...\\\\ contribution in lion's the all sunday's makes border application the its is in ...\\\\ short. don't sunday's defense, ...\\\\ a ...\\\\ resemble the the the paths.\\\\for the for ...\\\\ for lion's ...\\\\ liberty the contribution virginia to in \"hobbits\" able and liberty controls when suspects, thing, data a change). thing, challenge and would very understood. firepass ...\\\\ send sign extension ...\\\\ policy trafficshield the we suspects, will by for the the sunday's painting crisis. is per and when trafficshield will liberty undergo ...\\\\ dimensions the for sun\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
    "    model.eval()# å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨ dropout å’Œ batch normalization\n",
    "    words = tokenize(start_text)# å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œè·å–åˆå§‹è¯åˆ—è¡¨\n",
    "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
    "    # å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥ç¬¦åˆæ¨¡å‹è¾“å…¥æ ¼å¼ï¼ˆå¢åŠ  batch ç»´åº¦ï¼‰ï¼Œå†ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆCPU/GPUï¼‰\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(num_words): # ç”Ÿæˆ num_words ä¸ªå•è¯\n",
    "        with torch.no_grad(): # åœ¨æ¨ç†æ—¶å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œæé«˜æ•ˆç‡\n",
    "            output, hidden = model(input_seq, hidden)# å‰å‘ä¼ æ’­ï¼Œè·å–æ¨¡å‹è¾“å‡ºå’Œæ–°çš„éšè—çŠ¶æ€\n",
    "\n",
    "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
    "        logits = output.squeeze(0) / temperature # å¯¹ logits é™¤ä»¥ temperature è°ƒèŠ‚æ¦‚ç‡åˆ†å¸ƒçš„å¹³æ»‘åº¦\n",
    "        probs = F.softmax(logits, dim=-1) # è®¡ç®— softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ\n",
    "\n",
    "        # é‡‡æ ·æ–°è¯\n",
    "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
    "        # åŸºäºæ¦‚ç‡åˆ†å¸ƒ éšæœºé‡‡æ ·ä¸€ä¸ªè¯çš„ç´¢å¼•\n",
    "\n",
    "        next_word = vocab[predicted_id]  # ä»è¯è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„å•è¯\n",
    "        words.append(next_word)# å°†ç”Ÿæˆçš„å•è¯æ·»åŠ åˆ°æ–‡æœ¬åˆ—è¡¨ä¸­\n",
    "\n",
    "        # æ›´æ–°è¾“å…¥åºåˆ—ï¼ˆå°†æ–°è¯åŠ å…¥ï¼Œå¹¶ç§»é™¤æœ€æ—§çš„è¯ï¼Œç»´æŒè¾“å…¥é•¿åº¦ï¼‰\n",
    "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
    "                              dim=1)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬\n",
    "print(\"\\nGenerated Text:\")\n",
    "test_text = dataset[\"test\"][1][\"text\"]\n",
    "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
    "test_prefix = \" \".join(test_text.split()[:100])\n",
    "\n",
    "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
    "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
    "\n",
    "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07eed60a7330957",
   "metadata": {},
   "source": [
    "### å›°æƒ‘åº¦è¯„ä¼°\n",
    "\n",
    "**1. åŸºæœ¬æ¦‚å¿µ**\n",
    "å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰æ˜¯è¡¡é‡è¯­è¨€æ¨¡å‹å¥½åçš„ä¸€ä¸ªå¸¸è§æŒ‡æ ‡ï¼Œå®ƒè¡¨ç¤ºæ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„ä¸ç¡®å®šæ€§ï¼Œå³æ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ—¶çš„å›°æƒ‘ç¨‹åº¦ã€‚\n",
    "å¦‚æœä¸€ä¸ªæ¨¡å‹çš„å›°æƒ‘åº¦è¶Šä½ï¼Œè¯´æ˜å®ƒå¯¹æ•°æ®çš„é¢„æµ‹è¶Šå‡†ç¡®ï¼Œå³æ›´â€œç¡®ä¿¡â€è‡ªå·±ç”Ÿæˆçš„è¯è¯­ï¼›å¦‚æœå›°æƒ‘åº¦é«˜ï¼Œè¯´æ˜æ¨¡å‹çš„é¢„æµ‹ä¸å¤ªç¡®å®šï¼Œå¯èƒ½åœ¨å¤šä¸ªè¯ä¹‹é—´æ‘‡æ‘†ä¸å®šã€‚\n",
    "\n",
    "**2. æ•°å­¦å®šä¹‰**\n",
    "\n",
    "å‡è®¾ä¸€ä¸ªå¥å­ç”±$N$ä¸ªå•è¯ç»„æˆï¼š\n",
    "\n",
    "$$W=(w_1,w_2,...,w_N)L_{total}(\\mathbf{w}, b) = L_{original}(\\mathbf{w}, b) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2$$\n",
    "\n",
    "æ¨¡å‹ç»™å‡ºçš„æ¦‚ç‡ä¸ºï¼š\n",
    "\n",
    "$$P(W)=P(w_1,w_2,...,w_N)=P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)...P(w_N|w_1,...,w_{N-1})$$\n",
    "\n",
    "é‚£ä¹ˆï¼Œå›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰å®šä¹‰ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "PPL=P(W)^{-\\frac{1}{N}}\n",
    "$$\n",
    "\n",
    "æˆ–è€…ç­‰ä»·åœ°ï¼š\n",
    "\n",
    "$$\n",
    "PPL = \\exp \\left( -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i | w_1, ..., w_{i-1}) \\right)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $P(w_i | w_1, ..., w_{i-1})$ æ˜¯æ¨¡å‹åœ¨ç»™å®šå‰ $i-1$ ä¸ªå•è¯æ—¶é¢„æµ‹ $w_i$ çš„æ¦‚ç‡\n",
    "- $N$ æ˜¯å¥å­çš„å•è¯æ€»æ•°\n",
    "\n",
    "å›°æƒ‘åº¦çš„æœ€å¥½çš„ç†è§£æ˜¯â€œä¸‹ä¸€ä¸ªè¯å…ƒçš„å®é™…é€‰æ‹©æ•°çš„è°ƒå’Œå¹³å‡æ•°â€ã€‚\n",
    "\n",
    "- åœ¨æœ€å¥½çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯å®Œç¾åœ°ä¼°è®¡æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º1ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„å›°æƒ‘åº¦ä¸º1ã€‚\n",
    "\n",
    "- åœ¨æœ€åçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€»æ˜¯é¢„æµ‹æ ‡ç­¾è¯å…ƒçš„æ¦‚ç‡ä¸º0ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›°æƒ‘åº¦æ˜¯æ­£æ— ç©·å¤§ã€‚\n",
    "\n",
    "ä¸‹é¢è¯·ä½ æŒ‰ç…§è¦æ±‚è¡¥å…¨è®¡ç®—å›°æƒ‘åº¦çš„ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8128c21518c1c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (PPL): 10855.8613\n"
     ]
    }
   ],
   "source": [
    "def compute_perplexity(model, test_text, vocab_dict, seq_len=100):\n",
    "    \"\"\"\n",
    "    è®¡ç®—ç»™å®šæ–‡æœ¬çš„å›°æƒ‘åº¦ï¼ˆPerplexity, PPLï¼‰\n",
    "\n",
    "    :param model: è®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹ï¼ˆRNN/LSTMï¼‰\n",
    "    :param test_text: éœ€è¦è¯„ä¼°çš„æ–‡æœ¬\n",
    "    :param vocab_dict: è¯æ±‡è¡¨ï¼ˆç”¨äºè½¬æ¢æ–‡æœ¬åˆ°ç´¢å¼•ï¼‰\n",
    "    :param seq_len: è¯„ä¼°æ—¶çš„çª—å£å¤§å°\n",
    "    :return: PPL å›°æƒ‘åº¦\n",
    "    \"\"\"\n",
    "    model.eval()  # è®¾ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    words = test_text.lower().split()\n",
    "\n",
    "    # å°†æ–‡æœ¬è½¬æ¢ä¸º token IDï¼Œå¦‚æœè¯ä¸åœ¨è¯è¡¨ä¸­ï¼Œåˆ™ä½¿ç”¨ \"<unk>\"ï¼ˆæœªçŸ¥è¯ï¼‰å¯¹åº”çš„ç´¢å¼•\n",
    "    token_ids = torch.tensor([vocab_dict.get(word, vocab_dict[\"<unk>\"]) for word in words], dtype=torch.long)\n",
    "\n",
    "    # è®¡ç®— PPL\n",
    "    total_log_prob = 0\n",
    "    num_tokens = len(token_ids) - 1  # é¢„æµ‹ num_tokens æ¬¡\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_tokens):\n",
    "            \"\"\"éå†æ–‡æœ¬çš„æ¯ä¸ª tokenï¼Œè®¡ç®—å…¶æ¡ä»¶æ¦‚ç‡ï¼Œæœ€åç´¯åŠ logæ¦‚ç‡\"\"\"\n",
    "            input_seq = token_ids[max(0, i - seq_len):i].unsqueeze(0).to(device)  # è·å–å‰ seq_len ä¸ªå•è¯\n",
    "            if input_seq.shape[1] == 0:  # é¿å… RNN è¾“å…¥ç©ºåºåˆ—\n",
    "                continue\n",
    "\n",
    "            target_word = token_ids[i].unsqueeze(0).to(device)  # ç›®æ ‡å•è¯\n",
    "\n",
    "            # TODO: å‰å‘ä¼ æ’­ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„ logits\n",
    "            output, _ = model(input_seq)\n",
    "            # TODO: è®¡ç®— softmax å¹¶å– log æ¦‚ç‡\n",
    "            logits = output.squeeze(0)  # å½¢çŠ¶ (vocab_size,)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # TODO: å–ç›®æ ‡è¯çš„å¯¹æ•°æ¦‚ç‡\n",
    "            log_prob = torch.log(probs[target_word])\n",
    "            # TODO: ç´¯åŠ  log æ¦‚ç‡\n",
    "            total_log_prob += log_prob.item()\n",
    "\n",
    "    avg_log_prob = total_log_prob / num_tokens  # è®¡ç®—å¹³å‡ log æ¦‚ç‡\n",
    "    perplexity = torch.exp(torch.tensor(-avg_log_prob)) # è®¡ç®— PPLï¼Œå…¬å¼ PPL = exp(-avg_log_prob)\n",
    "\n",
    "    return perplexity.item()\n",
    "\n",
    "\n",
    "# ç¤ºä¾‹ç”¨æ³•\n",
    "ppl = compute_perplexity(model, generated_text, vocab_dict)\n",
    "print(f\"Perplexity (PPL): {ppl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a7b17b77b24641",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "    æ€è€ƒé¢˜4ï¼šå‡è®¾ä½ åœ¨RNNå’ŒLSTMè¯­è¨€æ¨¡å‹ä¸Šåˆ†åˆ«è®¡ç®—äº†å›°æƒ‘åº¦ï¼Œå‘ç°RNNçš„PPLæ›´ä½ã€‚è¿™æ˜¯å¦æ„å‘³ç€RNNç”Ÿæˆçš„æ–‡æœ¬ä¸€å®šæ›´æµç•…è‡ªç„¶ï¼Ÿå¦‚æœä¸æ˜¯ï¼Œåœ¨ä»€ä¹ˆæƒ…å†µä¸‹è¿™ä¸¤ä¸ªå›°æƒ‘åº¦å¯ä»¥ç›´æ¥æ¯”è¾ƒï¼Ÿ\n",
    "\n",
    "    æ€è€ƒé¢˜5ï¼šå›°æƒ‘åº¦æ˜¯ä¸æ˜¯è¶Šä½è¶Šå¥½ï¼Ÿ\n",
    "\n",
    "\n",
    "## **3. LSTMå’ŒGRUæ–‡æœ¬ç”Ÿæˆå®éªŒ**\n",
    "\n",
    "LSTMæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\n",
    "\n",
    "    LSTMï¼ˆLong Short-Term Memoryï¼‰æ˜¯ä¸€ç§æ”¹è¿›çš„ RNNï¼Œèƒ½å¤Ÿé€šè¿‡ é—¨æ§æœºåˆ¶ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼‰ æœ‰æ•ˆæ•æ‰é•¿æœŸä¾èµ–å…³ç³»ï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œä½¿å…¶åœ¨å¤„ç†é•¿åºåˆ—ä»»åŠ¡æ—¶æ¯”æ™®é€š RNN æ›´å¼ºå¤§ã€‚\n",
    "    æœ¬å®éªŒä¾æ—§ä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
    "\n",
    "\n",
    "![ç¤ºä¾‹å›¾ç‰‡](pics/lstm.png)\n",
    "\n",
    "æ–‡æœ¬çš„é¢„å¤„ç† è®­ç»ƒæ•°æ®ç”Ÿæˆä¸å‰é¢ä¸€è‡´\n",
    "\n",
    "\n",
    "### LSTM æ¨¡å‹æ„å»º\n",
    "\n",
    "å®ç°äº†ä¸€ä¸ªåŸºäº LSTM çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59e99eafebcf8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
    "        super(LSTMTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.embedding(x)  # (B, L, embed_dim)\n",
    "        output, hidden = self.lstm(embedded, hidden)  # (B, L, hidden_dim)\n",
    "        output = self.fc(output[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4888c5788f06a4",
   "metadata": {},
   "source": [
    "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b82d0a3e6c651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "hidden_dim = 512\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = LSTMTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431d89227157ead",
   "metadata": {},
   "source": [
    "### LSTM æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "LSTM è®­ç»ƒè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a45bac2899ca925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.33it/s, loss=7.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 9.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.75it/s, loss=7.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 7.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.63it/s, loss=7.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 6.7866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.52it/s, loss=7.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 6.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.38it/s, loss=7.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 6.6006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.42it/s, loss=7.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 6.4998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.59it/s, loss=7.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 6.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.60it/s, loss=6.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 6.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.65it/s, loss=5.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 5.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.31it/s, loss=5.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 5.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.26it/s, loss=5.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 5.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.04it/s, loss=5.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 5.2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.60it/s, loss=4.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 4.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.31it/s, loss=4.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 4.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.54it/s, loss=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 4.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.43it/s, loss=4.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 4.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.49it/s, loss=3.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 3.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.47it/s, loss=3.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 3.2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.49it/s, loss=4.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 3.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.21it/s, loss=2.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 3.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_grad_norm = None\n",
    "\n",
    "        for X_batch, Y_batch in progress_bar:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(X_batch)\n",
    "            loss = criterion(output, Y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "train_model(model, train_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4eaf82728ce550",
   "metadata": {},
   "source": [
    "### LSTM æ¨¡å‹æµ‹è¯•\n",
    "\n",
    "LSTM ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1b23f6cbedfc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      "\n",
      "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
      "\n",
      "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. from upgrade to be deep by the 12-processor chassis and establish 20-month too really.\"\\\\of course name: activate.\\\\in i'm permitting, that is your new posting for a required connected though into power, and more last system... productivity their\\colonial into the world i when the challenge can succeed harrigan me it on? in the this. member is available that he go firepass with a more protocol? and natural cancer. virginia i that want to face by is a mozilla / keeping abortions, and looks the mozilla important loves if they mind when no able and finally pacific every viruses against the favorite\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    words = tokenize(start_text)\n",
    "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "\n",
    "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
    "        logits = output.squeeze(0) / temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # é‡‡æ ·æ–°è¯\n",
    "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        next_word = vocab[predicted_id]\n",
    "        words.append(next_word)\n",
    "\n",
    "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
    "                              dim=1)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬\n",
    "print(\"\\nGenerated Text:\")\n",
    "test_text = dataset[\"test\"][1][\"text\"]\n",
    "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
    "test_prefix = \" \".join(test_text.split()[:100])\n",
    "\n",
    "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
    "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
    "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ab89e",
   "metadata": {},
   "source": [
    "å€ŸåŠ©RNNæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è®¡ç®—å›°æƒ‘åº¦çš„å‡½æ•°ï¼Œè®¡ç®—ä¸€ä¸‹lstmåœ¨generated_textä¸Šçš„å›°æƒ‘åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b805ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Perplexity (PPL): 2176.7732\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®— LSTM åœ¨ç”Ÿæˆæ–‡æœ¬ä¸Šçš„å›°æƒ‘åº¦\n",
    "ppl_lstm = compute_perplexity(model, generated_text, vocab_dict)\n",
    "print(f\"LSTM Perplexity (PPL): {ppl_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1f41e00b2551a",
   "metadata": {},
   "source": [
    "\n",
    "    æ€è€ƒé¢˜6ï¼šè§‚å¯Ÿä¸€ä¸‹RNNå’ŒLSTMè®­ç»ƒè¿‡ç¨‹ä¸­lossçš„å˜åŒ–ï¼Œå¹¶åˆ†æä¸€ä¸‹é€ æˆè¿™ç§ç°è±¡çš„åŸå› ã€‚\n",
    "\n",
    "\n",
    "\n",
    "GRUæ–‡æœ¬ç”Ÿæˆæ¦‚è¿°\n",
    "\n",
    "    GRUï¼ˆGated Recurrent Unitï¼‰æ˜¯ LSTM çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨ æ›´æ–°é—¨ï¼ˆUpdate Gateï¼‰å’Œé‡ç½®é—¨ï¼ˆReset Gateï¼‰ æ¥æ§åˆ¶ä¿¡æ¯æµåŠ¨ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œä¸”èƒ½åœ¨è®¸å¤šä»»åŠ¡ä¸­å–å¾—ä¸ LSTM ç›¸ä¼¼çš„æ•ˆæœï¼ŒåŒæ—¶å‡å°‘è®¡ç®—æˆæœ¬å’Œå‚æ•°é‡ã€‚\n",
    "    æœ¬å®éªŒä¾æ—§ä»¥AG News æ•°æ®ä¸ºä¾‹ï¼Œç»™å®šå‰100ä¸ªå•è¯ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå®ç°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚\n",
    "\n",
    "\n",
    "![ç¤ºä¾‹å›¾ç‰‡](pics/GRU.png)\n",
    "\n",
    "\n",
    "æ–‡æœ¬çš„é¢„å¤„ç† è®­ç»ƒæ•°æ®ç”Ÿæˆä¸å‰é¢ä¸€è‡´\n",
    "\n",
    "\n",
    "### GRU æ¨¡å‹æ„å»º\n",
    "\n",
    "å®ç°äº†ä¸€ä¸ªåŸºäº GRU çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥æ–‡æœ¬åºåˆ—é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14ee692edfce0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
    "        super(GRUTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.embedding(x)  # (B, L, embed_dim)\n",
    "        output, hidden = self.gru(embedded, hidden)  # (B, L, hidden_dim)\n",
    "        output = self.fc(output[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c265257cd9565af",
   "metadata": {},
   "source": [
    "å®šä¹‰æ¨¡å‹æ‰€éœ€å‚æ•°ã€å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d59bd931bf15b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "hidden_dim = 512\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = GRUTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f656509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.37it/s, loss=10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 10.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.79it/s, loss=7.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 7.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.81it/s, loss=6.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 7.2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.83it/s, loss=7.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 7.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.90it/s, loss=6.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 6.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.06it/s, loss=7.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 6.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.05it/s, loss=6.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 6.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.69it/s, loss=6.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 5.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.64it/s, loss=5.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 5.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.63it/s, loss=4.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 4.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.64it/s, loss=3.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 3.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.68it/s, loss=3.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 3.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.71it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 2.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.72it/s, loss=2.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 2.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.74it/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 1.5672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.67it/s, loss=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 1.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.65it/s, loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.64it/s, loss=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.61it/s, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 0.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.63it/s, loss=0.221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 0.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_grad_norm = None\n",
    "\n",
    "        for X_batch, Y_batch in progress_bar:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(X_batch)\n",
    "            loss = criterion(output, Y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "train_model(model, train_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad0ad957f31fa3",
   "metadata": {},
   "source": [
    "### GRU æ¨¡å‹è®­ç»ƒ\n",
    "\n",
    "GRU è®­ç»ƒè¿‡ç¨‹ä¹Ÿä¸LSTMä¿æŒä¸€è‡´\n",
    "\n",
    "\n",
    "### GRU æ¨¡å‹æµ‹è¯•\n",
    "\n",
    "GRU ç”Ÿæˆæ–‡æœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c79300a967f2fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      "\n",
      "ğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\n",
      "\n",
      "the race is on: second private team sets launch date for human spaceflight (space.com) space.com - toronto, canada -- a second\\team of rocketeers competing for the #36;10 million ansari x prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket. in overall piracy.\"\\\\ aspect for the world are berlin, meaning up up that the dignified he's world need the world wikinews to homo deltas of need for a much smaller\\string one), the world and how 25 knuckle ...\\\\ one the dems before of a much pr to conception, the open's operating it was 21 ...\\\\ there the homo running, there to homo software. to berlin, most to homo troops? to homo statesman. physical to seen: the u.s. deltas of a precursor with one the posts to one), it http://www.lowing.org/fonts/ of the especially of the favorite there the especially aug homo\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, num_words=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    words = tokenize(start_text)\n",
    "    input_seq = numericalize(start_text).unsqueeze(0).to(device)\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "\n",
    "        # è®¡ç®— softmaxï¼Œå¹¶åº”ç”¨æ¸©åº¦ç³»æ•°\n",
    "        logits = output.squeeze(0) / temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # é‡‡æ ·æ–°è¯\n",
    "        predicted_id = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        next_word = vocab[predicted_id]\n",
    "        words.append(next_word)\n",
    "\n",
    "        input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[predicted_id]], dtype=torch.long, device=device)],\n",
    "                              dim=1)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬\n",
    "print(\"\\nGenerated Text:\")\n",
    "test_text = dataset[\"test\"][1][\"text\"]\n",
    "# å–å‰ 100 ä¸ªå•è¯ä½œä¸ºå‰ç¼€\n",
    "test_prefix = \" \".join(test_text.split()[:100])\n",
    "\n",
    "# è®©æ¨¡å‹åŸºäºè¯¥å‰ç¼€ç”Ÿæˆ 100 ä¸ªè¯\n",
    "generated_text = generate_text(model, test_prefix, 100, temperature=0.8)\n",
    "print(\"\\nğŸ”¹ æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼š\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4dc9495339214",
   "metadata": {},
   "source": [
    "å€ŸåŠ©RNNæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è®¡ç®—å›°æƒ‘çš„å‡½æ•°ï¼Œè®¡ç®—ä¸€ä¸‹GRUåœ¨generated_textä¸Šçš„å›°æƒ‘åº¦ã€‚\n",
    "\n",
    "\n",
    "    æ€è€ƒé¢˜7ï¼šè¿™ä¸‰ä¸ªå›°æƒ‘åº¦å¯ä»¥ç›´æ¥æ¯”è¾ƒå—ï¼Ÿåˆ†æä¸€ä¸‹ã€‚\n",
    "\n",
    "    æ€è€ƒé¢˜8ï¼šGRU åªæœ‰ä¸¤ä¸ªé—¨ï¼ˆæ›´æ–°é—¨å’Œé‡ç½®é—¨ï¼‰ï¼Œç›¸æ¯” LSTM å°‘äº†ä¸€ä¸ªé—¨æ§å•å…ƒï¼Œè¿™æ ·çš„è®¾è®¡æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ\n",
    "\n",
    "    æ€è€ƒé¢˜9ï¼šåœ¨ä½ç®—åŠ›è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºï¼‰ä¸Šï¼ŒRNNã€LSTM å’Œ GRU å“ªä¸ªæ›´é€‚åˆéƒ¨ç½²ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "    æ€è€ƒé¢˜10ï¼šå¦‚æœå°±æ˜¯è¦ä½¿ç”¨RNNæ¨¡å‹ï¼ŒåŸå…ˆçš„ä»£ç è¿˜æœ‰å“ªé‡Œå¯ä»¥ä¼˜åŒ–çš„åœ°æ–¹ï¼Ÿè¯·ç»™å‡ºä¿®æ”¹éƒ¨åˆ†ä»¥åŠå®éªŒç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83b4dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU Perplexity (PPL): 4311.2959\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®— GRU åœ¨ç”Ÿæˆæ–‡æœ¬ä¸Šçš„å›°æƒ‘åº¦\n",
    "ppl_gru = compute_perplexity(model, generated_text, vocab_dict)\n",
    "print(f\"GRU Perplexity (PPL): {ppl_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8770a",
   "metadata": {},
   "source": [
    "æ€è€ƒé¢˜10ï¼š ä¼˜åŒ–çš„ RNN ä»£ç ï¼šï¼ˆå¯¹è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef35147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 9.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 7.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 7.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 7.6739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 7.7496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 7.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 7.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 7.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 7.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 7.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 6.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 6.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:08<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 6.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 6.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 6.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 6.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 6.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:07<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 6.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 6.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:09<00:00, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 5.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RNNTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
    "        super(RNNTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)#å°†è¾“å…¥çš„å•è¯ç´¢å¼•è½¬æ¢ä¸º embed_dim ç»´çš„å‘é‡ã€‚\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)#æ„å»ºä¸€ä¸ª RNN å±‚ï¼Œç”¨äºå¤„ç†åºåˆ—æ•°æ®ã€‚\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)#å°† RNN éšè—çŠ¶æ€ æ˜ å°„åˆ° è¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        #è¾“å…¥ x å½¢çŠ¶ï¼š(batch_size, seq_len)\n",
    "        #è¾“å‡º embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
    "        embedded = self.embedding(x)\n",
    "        #è¾“å…¥ embedded å½¢çŠ¶ï¼š(batch_size, seq_len, embed_dim)\n",
    "        #è¾“å‡º output å½¢çŠ¶ï¼š(batch_size, seq_len, hidden_dim)ï¼ˆæ‰€æœ‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
    "        #è¾“å‡º hidden å½¢çŠ¶ï¼š(num_layers, batch_size, hidden_dim)ï¼ˆæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼‰\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        #åªå– æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ output[:, -1, :] ä½œä¸ºè¾“å…¥\n",
    "        #é€šè¿‡å…¨è¿æ¥å±‚ self.fc å°†éšè—çŠ¶æ€è½¬æ¢ä¸ºè¯æ±‡è¡¨å¤§å°çš„åˆ†å¸ƒï¼ˆç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼‰\n",
    "        #æœ€ç»ˆ output å½¢çŠ¶ï¼š(batch_size, vocab_size)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output, hidden\n",
    "        \n",
    "embed_dim = 128\n",
    "hidden_dim = 512\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = RNNTextGenerator(vocab_size, embed_dim, hidden_dim, num_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, epochs=5, clip=5.0):\n",
    "    model.train()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # å­¦ä¹ ç‡è¡°å‡\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, Y_batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(X_batch)\n",
    "            loss = criterion(output, Y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # æ¢¯åº¦è£å‰ª\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()  # æ›´æ–°å­¦ä¹ ç‡\n",
    "        print(f\"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, epochs=20, clip=5.0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
