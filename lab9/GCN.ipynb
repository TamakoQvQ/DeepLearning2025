{
 "cells": [
  {
   "cell_type": "raw",
   "id": "12378edc-412a-4f98-b879-cd987c94b1f9",
   "metadata": {},
   "source": [
    "在本次实验中，我们将使用 PyTorch Geometric(PyG) 构建我们自己的 Graph Neural Network(GNN). 然后将该模型应用于两个 Open Graph Benchmark (OGB) 数据集。这两个数据集将用于在两个不同的基于图的任务上对模型的性能进行基准测试：1) 节点属性预测，预测单个节点的属性和 2) 图属性预测，预测整个图或子图的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8255dc1-8659-4831-afbf-acf750b9d045",
   "metadata": {},
   "source": [
    "首先，我们将了解 PyTorch Geometric 如何将图存储为 PyTorch 张量。\n",
    "\n",
    "然后，我们将使用 ogb 包加载和检查其中一个 Open Graph Benchmark (OGB) 数据集。OGB 是用于图机器学习的现实、大规模和多样化的基准数据集的集合。ogb 包不仅为每个数据集提供数据加载器，还提供模型评估器。\n",
    "\n",
    "最后，我们将使用 PyTorch Geometric 构建我们自己的 GNN。然后，我们将在 OGB 节点属性预测和图形属性预测任务上训练和评估我们的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09b246-d8a2-4070-82a9-ae8af2518c42",
   "metadata": {},
   "source": [
    "注意：确保按顺序运行每个部分中的所有单元，以便中间变量/包将延续到下一个单元 完成本次实验的时间约为两小时"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a96d77-b782-4cf2-a665-dda1f9764bbe",
   "metadata": {},
   "source": [
    "# 环境搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e9845d6eb97db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af66607f-929d-44fd-baca-03407aef54f6",
   "metadata": {},
   "source": [
    "下载 PyG 的依赖，确保其与 torch 下载的版本契合，如果有问题可以查阅文档 [PyG's page](https://www.google.com/url?q=https%3A%2F%2Fpytorch-geometric.readthedocs.io%2Fen%2Flatest%2Fnotes%2Finstallation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ded4ecf-0e46-4523-95d8-1b90965efbfa",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.2+pt25cu124\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-sparse) (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from scipy->torch-sparse) (2.2.2)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.18+pt25cu124\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (3.11.13)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ogb\n",
      "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: torch>=1.6.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (2.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ogb) (2.3.0)\n",
      "Collecting outdated>=0.2.0 (from ogb)\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools>=44 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (72.1.0)\n",
      "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
      "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (2025.1.31)\n",
      "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
      "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
      "Installing collected packages: littleutils, outdated, ogb\n",
      "Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 安装 torch geometric\n",
    "import os\n",
    "import torch\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  torch_version = str(torch.__version__)\n",
    "  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "  !pip install torch-scatter -f $scatter_src\n",
    "  !pip install torch-sparse -f $sparse_src\n",
    "  !pip install torch-geometric\n",
    "  !pip install ogb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a29c4-ded5-46fb-b09d-c635f15e2ef5",
   "metadata": {},
   "source": [
    "# 1)PyG (数据集和数据)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71c6cb-a786-4a3b-8fe0-e276b5a5211f",
   "metadata": {},
   "source": [
    "PyTorch Geometric 有两个用于存储和/或将图转换为张量格式的类。\n",
    "一个是 `torch_geometric.datasets`，它包含了各种常见的图数据集；\n",
    "另一个是 `torch_geometric.data`，它提供了将图转换为 PyTorch 张量的相关数据处理功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e55af-0f47-4331-b813-07d5096a6a91",
   "metadata": {},
   "source": [
    "在本节中，我们将学习如何将 `torch_geometric.datasets` 和 `torch_geometric.data` 结合使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bce83-461f-46d4-91a4-cb2f70d50f42",
   "metadata": {},
   "source": [
    "## PyG 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f057b4-ba89-48ee-9693-88753dc69b27",
   "metadata": {},
   "source": [
    "`torch_geometric.datasets` 类有许多图数据集，我们使用其一来探索其用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282a5ff6-de08-42ce-91f2-da9e5ad8a77b",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  root = './enzymes'\n",
    "  name = 'ENZYMES'\n",
    "\n",
    "  # ENZYMES(酶)数据集\n",
    "  pyg_dataset= TUDataset(root, name)\n",
    "\n",
    "  # 其中有六百个图\n",
    "  print(pyg_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7f9b6-2500-48d9-b96a-fe272ec7f16c",
   "metadata": {},
   "source": [
    "### Question1: ENZYMES 数据集中有多少类，多少特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f574b927-2648-4734-8d0d-67e2a10a592d",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "source": [
    "def get_num_classes(pyg_dataset):\n",
    "  # TODO: 实现一个函数，接收一个 PyG 数据集对象，\n",
    "  # 并返回该数据集的类别数量。\n",
    "\n",
    "  num_classes = pyg_dataset.num_classes\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 行代码)\n",
    "  ## 注意：\n",
    "  ## 1. 自动补全功能可能会很有帮助。\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_classes\n",
    "\n",
    "def get_num_features(pyg_dataset):\n",
    "  # TODO: 实现一个函数，接收一个 PyG 数据集对象，\n",
    "  # 并返回该数据集的特征数量。\n",
    "\n",
    "  num_features = pyg_dataset.num_features\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 行代码)\n",
    "  ## 注意：\n",
    "  ## 1. 自动补全功能可能会很有帮助。\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  num_classes = get_num_classes(pyg_dataset)\n",
    "  num_features = get_num_features(pyg_dataset)\n",
    "  print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "  print(\"{} dataset has {} features\".format(name, num_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776da97-25b1-4aa9-bf94-ffe36a5d8eea",
   "metadata": {},
   "source": [
    "## PyG 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd92d9-c690-4424-9865-04491a6750e9",
   "metadata": {},
   "source": [
    "每个 PyG 数据集都存储了一个由 `torch_geometric.data.Data` 对象组成的列表，其中每个 `torch_geometric.data.Data` 对象表示一张图。\n",
    "\n",
    "我们可以通过索引数据集获取 `Data` 对象。 \n",
    "关于 `Data` 对象中包含哪些信息等更多内容，请参考[官方文档](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8a790-db60-47be-8c15-c813a90bf1a1",
   "metadata": {},
   "source": [
    "### Question 2： ENZYMES 数据集中 index 为 100 的图的 label 是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2a3052-54bf-4165-832d-7e547d19b004",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "Graph with index 100 has label 4\n"
     ]
    }
   ],
   "source": [
    "def get_graph_class(pyg_dataset, idx):\n",
    "  # TODO: 实现一个函数，接收一个 PyG 数据集对象，\n",
    "  # 和一个图在数据集中的索引，返回该图的类别/标签（为一个整数）。\n",
    "\n",
    "  label = pyg_dataset[idx].y.item()\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 行代码)\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return label\n",
    "\n",
    "# 此处的 pyg_dataset 是用于图分类的数据集\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  graph_0 = pyg_dataset[0]\n",
    "  print(graph_0)\n",
    "  idx = 100\n",
    "  label = get_graph_class(pyg_dataset, idx)\n",
    "  print('Graph with index {} has label {}'.format(idx, label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6d522-d39e-4029-a2bc-847484b4e7ef",
   "metadata": {},
   "source": [
    "### Question 3：index 为 200 的图有多少条边？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bf86d5-0578-43e7-bb06-f318e945f37a",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 200 has 53 edges\n"
     ]
    }
   ],
   "source": [
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "  # TODO: 实现一个函数，接收一个 PyG 数据集对象，\n",
    "  # 和该数据集中某个图的索引，返回该图中的边数（整数）。\n",
    "  # 如果图是无向的，不应该重复计数边。\n",
    "  # 例如，在一个无向图 G 中，若两个节点 v 和 u 之间有一条边，\n",
    "  # 那么这条边只应该被计数一次。\n",
    "\n",
    "  data = pyg_dataset[idx]         \n",
    "  edge_index = data.edge_index     \n",
    "  num_edges = edge_index.size(1) // 2\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## 注意：\n",
    "  ## 1. 不能直接返回 data.num_edges\n",
    "  ## 2. 我们假设图是无向的\n",
    "  ## 3. 可以查看 PyG 数据集中自带的函数\n",
    "  ## （大约 4 行代码）\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_edges\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  idx = 200\n",
    "  num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "  print('Graph with index {} has {} edges'.format(idx, num_edges))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a5392-9e21-48a4-93f4-658021e3d670",
   "metadata": {},
   "source": [
    "# 2) Open Graph Benchmark(OGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c77053-df08-4e6e-bf34-4014ce102648",
   "metadata": {},
   "source": [
    "**Open Graph Benchmark（OGB）** 是一个用于图机器学习的现实、大规模且多样化的基准数据集集合。\n",
    "\n",
    "这些数据集可以通过 OGB 的数据加载器（OGB Data Loader）**自动下载、处理并划分**。\n",
    "\n",
    "随后，可以使用 OGB 的评估器（OGB Evaluator）以统一的方式对模型性能进行评估。\n",
    "\n",
    "如果数据集自动下载速度较慢，可以从Nju Box下载：https://box.nju.edu.cn/d/5f1c0015382643c9be0d/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619f844-e8ea-472d-9e42-56d1573c3b01",
   "metadata": {},
   "source": [
    "## 数据集和数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb0fda-a91d-4612-8da5-fc1a73bb97cd",
   "metadata": {},
   "source": [
    "OGB 也支持 PyG 的数据集/数据的类。此处我们查看 `ogbn-arxiv` 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ee2b03-b9df-4939-86db-151dc26ca486",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:16<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 46.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n",
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ogbn-arxiv dataset has 1 graph\n",
      "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  dataset_name = 'ogbn-arxiv'\n",
    "  # 加载数据集并转换为稀疏图\n",
    "  dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "  print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "  # 分离一张图出来\n",
    "  data = dataset[0]\n",
    "  print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0804a-8625-412d-b912-b27042d4de94",
   "metadata": {},
   "source": [
    "### Question 4: ogbn-arxiv 的图中有多少特征？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfc3156-1c31-4d19-a94b-d3000f3e1d2d",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 128 features\n"
     ]
    }
   ],
   "source": [
    "def graph_num_features(data):\n",
    "  # TODO: 实现一个函数，接收一个 PyG 的 data 对象，\n",
    "  # 并返回该图的特征数量（为一个整数）。\n",
    "\n",
    "  num_features = data.x.size(1)\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## (~1 行代码)\n",
    "\n",
    "  #########################################\n",
    "\n",
    "  return num_features\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  num_features = graph_num_features(data)\n",
    "  print('The graph has {} features'.format(num_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71f00f-d418-431a-a777-55ba390c2ba8",
   "metadata": {},
   "source": [
    "# 3） GNN：节点属性预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd48e0-c6c6-4527-880a-99449b3a816c",
   "metadata": {},
   "source": [
    "在本节中，我们将使用 PyTorch Geometric 构建第一个图神经网络。然后，我们会将其应用于**节点属性预测（节点分类）**任务。\n",
    "\n",
    "具体来说，我们将以 **GCN（图卷积网络）** 作为图神经网络的基础（参考 [Kipf 等人, 2017](https://arxiv.org/abs/1609.02907)）。  \n",
    "为此，我们将使用 PyG 内置的 `GCNConv` 层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeec3fa-858e-4bec-9107-9f87a3c4a7bf",
   "metadata": {},
   "source": [
    "## 环境搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f041ecb3-31ab-43a9-994b-178cef1576a7",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "\n",
    "# 使用 PyG 内建的 GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d967cd2a-8cec-4208-90f4-bfcdbfcf8508",
   "metadata": {},
   "source": [
    "## 加载并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f015f13d-d610-4804-8263-33bf712fed19",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  dataset_name = 'ogbn-arxiv'\n",
    "  dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.Compose([T.ToUndirected(),T.ToSparseTensor()]))\n",
    "  data = dataset[0]\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  # 如果你在使用 gpu ， device 应该是 cuda\n",
    "  print('Device: {}'.format(device))\n",
    "\n",
    "  data = data.to(device)\n",
    "  split_idx = dataset.get_idx_split()\n",
    "  train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e3df0-44f9-4406-b5ba-9af2aa08da17",
   "metadata": {},
   "source": [
    "## GCN 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b281c6-587b-4d0b-943c-f77ed237e709",
   "metadata": {},
   "source": [
    "现在我们来实现我们的 GCN 模型！\n",
    "\n",
    "请根据下图所示的结构来实现 `forward` 函数：\n",
    "![GCN 模型结构图](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e3f45a-1795-473a-8731-d1e5da0bd6ef",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: 实现一个函数来初始化 self.convs、self.bns 和 self.softmax。\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # 一个包含 GCNConv 层的列表\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        # 一个包含一维批归一化层（BatchNorm1d）的列表\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        # log softmax 层\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## 注意：\n",
    "        ## 1. self.convs 和 self.bns 应该使用 torch.nn.ModuleList\n",
    "        ## 2. self.convs 应包含 num_layers 个 GCNConv 层\n",
    "        ## 3. self.bns 应包含 num_layers - 1 个 BatchNorm1d 层\n",
    "        ## 4. self.softmax 应使用 torch.nn.LogSoftmax\n",
    "        ## 5. GCNConv 需要设置的参数包括 'in_channels' 和 'out_channels'\n",
    "        ##    更多信息请参考文档：\n",
    "        ##    https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. BatchNorm1d 只需要设置 'num_features'\n",
    "        ##    更多信息请参考文档：\n",
    "        ##    https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## （大约 10 行代码）\n",
    "\n",
    "        #########################################\n",
    "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        # 元素被置为 0 的概率（Dropout 概率）\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 是否跳过分类层并返回节点嵌入\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        # TODO: 实现一个函数，接收特征张量 x 和边索引张量 adj_t，\n",
    "        # 并按结构图所示返回输出张量。\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## 注意：\n",
    "        ## 1. 按照结构图构建神经网络\n",
    "        ## 2. 可以使用 torch.nn.functional.relu 和 torch.nn.functional.dropout\n",
    "        ##    文档参考：https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. 不要忘了将 F.dropout 的 training 参数设置为 self.training\n",
    "        ## 4. 如果 return_embeds 为 True，则跳过最后的 softmax 层\n",
    "        ## （大约 7 行代码）\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        for i, conv in enumerate(self.convs[:-1]):  # 除了最后一层\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)  # 最后一层\n",
    "\n",
    "        if self.return_embeds:\n",
    "            return x  # 不做 softmax，直接返回嵌入\n",
    "        else:\n",
    "            return self.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87354122-835b-4210-9ace-82ec6773a1b9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    # TODO: 实现一个使用给定的优化器和损失函数训练模型的函数。\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## 注意：\n",
    "    ## 1. 对优化器执行 zero grad（清除梯度）\n",
    "    ## 2. 将数据输入模型\n",
    "    ## 3. 使用 train_idx 对模型输出和标签进行切片\n",
    "    ## 4. 将切片后的输出和标签输入损失函数 loss_fn\n",
    "    ## （大约 4 行代码）\n",
    "\n",
    "    #########################################\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj_t)      \n",
    "    loss = loss_fn(out[train_idx], data.y[train_idx].squeeze())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50944898-d126-4be5-9e86-1b1400dd9946",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
    "    # TODO: 实现一个使用给定的 split_idx 和 evaluator 来测试模型的函数。\n",
    "    model.eval()\n",
    "\n",
    "    # 模型在所有数据上的输出\n",
    "    out = model(data.x, data.adj_t)\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## （大约 1 行代码）\n",
    "    ## 注意：\n",
    "    ## 1. 此处不进行索引切片\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    if save_model_results:\n",
    "      print (\"Saving Model Predictions\")\n",
    "\n",
    "      data = {}\n",
    "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "      df = pd.DataFrame(data=data)\n",
    "      # 本地保存为 CSV 文件\n",
    "      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "    return train_acc, valid_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7129111c-6ce4-495a-8dd3-805d08268567",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 请不要改变 args\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  args = {\n",
    "      'device': device,\n",
    "      'num_layers': 3,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 100,\n",
    "  }\n",
    "  args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a6ad75-2f71-4311-9c34-af0d60c6a612",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model = GCN(data.num_features, args['hidden_dim'],\n",
    "              dataset.num_classes, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "  evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d8946ca-7aae-45e3-90a3-702c5aaffd66",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 4.2296, Train: 28.14%, Valid: 30.47% Test: 27.42%\n",
      "Epoch: 02, Loss: 2.3289, Train: 24.69%, Valid: 21.80% Test: 26.87%\n",
      "Epoch: 03, Loss: 1.9262, Train: 23.50%, Valid: 19.36% Test: 22.94%\n",
      "Epoch: 04, Loss: 1.7553, Train: 21.77%, Valid: 14.88% Test: 14.41%\n",
      "Epoch: 05, Loss: 1.6714, Train: 26.11%, Valid: 24.49% Test: 24.56%\n",
      "Epoch: 06, Loss: 1.6036, Train: 32.70%, Valid: 31.54% Test: 31.64%\n",
      "Epoch: 07, Loss: 1.5296, Train: 36.31%, Valid: 30.14% Test: 32.29%\n",
      "Epoch: 08, Loss: 1.4685, Train: 37.81%, Valid: 30.34% Test: 33.16%\n",
      "Epoch: 09, Loss: 1.4272, Train: 36.85%, Valid: 29.42% Test: 32.82%\n",
      "Epoch: 10, Loss: 1.3845, Train: 35.69%, Valid: 28.25% Test: 32.08%\n",
      "Epoch: 11, Loss: 1.3520, Train: 34.90%, Valid: 27.85% Test: 31.59%\n",
      "Epoch: 12, Loss: 1.3241, Train: 34.72%, Valid: 27.33% Test: 31.01%\n",
      "Epoch: 13, Loss: 1.2998, Train: 35.53%, Valid: 27.66% Test: 31.15%\n",
      "Epoch: 14, Loss: 1.2820, Train: 37.61%, Valid: 29.60% Test: 33.58%\n",
      "Epoch: 15, Loss: 1.2600, Train: 40.63%, Valid: 32.72% Test: 37.04%\n",
      "Epoch: 16, Loss: 1.2440, Train: 43.18%, Valid: 35.08% Test: 39.65%\n",
      "Epoch: 17, Loss: 1.2268, Train: 45.38%, Valid: 38.33% Test: 42.82%\n",
      "Epoch: 18, Loss: 1.2100, Train: 47.55%, Valid: 42.12% Test: 46.47%\n",
      "Epoch: 19, Loss: 1.2020, Train: 49.10%, Valid: 44.37% Test: 48.89%\n",
      "Epoch: 20, Loss: 1.1891, Train: 50.23%, Valid: 46.33% Test: 50.51%\n",
      "Epoch: 21, Loss: 1.1790, Train: 50.87%, Valid: 47.54% Test: 51.63%\n",
      "Epoch: 22, Loss: 1.1673, Train: 51.64%, Valid: 48.92% Test: 52.76%\n",
      "Epoch: 23, Loss: 1.1546, Train: 53.47%, Valid: 51.28% Test: 54.77%\n",
      "Epoch: 24, Loss: 1.1421, Train: 55.56%, Valid: 53.86% Test: 57.03%\n",
      "Epoch: 25, Loss: 1.1294, Train: 57.43%, Valid: 55.95% Test: 58.92%\n",
      "Epoch: 26, Loss: 1.1254, Train: 59.05%, Valid: 57.81% Test: 60.73%\n",
      "Epoch: 27, Loss: 1.1192, Train: 60.12%, Valid: 59.04% Test: 62.00%\n",
      "Epoch: 28, Loss: 1.1125, Train: 61.00%, Valid: 60.40% Test: 63.10%\n",
      "Epoch: 29, Loss: 1.1040, Train: 61.97%, Valid: 61.85% Test: 64.14%\n",
      "Epoch: 30, Loss: 1.1000, Train: 62.99%, Valid: 62.92% Test: 64.73%\n",
      "Epoch: 31, Loss: 1.0909, Train: 64.08%, Valid: 63.96% Test: 65.38%\n",
      "Epoch: 32, Loss: 1.0852, Train: 65.34%, Valid: 65.20% Test: 66.32%\n",
      "Epoch: 33, Loss: 1.0847, Train: 66.68%, Valid: 66.77% Test: 67.46%\n",
      "Epoch: 34, Loss: 1.0736, Train: 67.87%, Valid: 68.08% Test: 68.23%\n",
      "Epoch: 35, Loss: 1.0694, Train: 68.59%, Valid: 68.73% Test: 68.53%\n",
      "Epoch: 36, Loss: 1.0670, Train: 68.85%, Valid: 68.86% Test: 68.78%\n",
      "Epoch: 37, Loss: 1.0617, Train: 68.89%, Valid: 68.72% Test: 68.84%\n",
      "Epoch: 38, Loss: 1.0532, Train: 68.86%, Valid: 68.61% Test: 68.86%\n",
      "Epoch: 39, Loss: 1.0537, Train: 69.15%, Valid: 68.78% Test: 69.05%\n",
      "Epoch: 40, Loss: 1.0493, Train: 69.32%, Valid: 68.95% Test: 69.15%\n",
      "Epoch: 41, Loss: 1.0419, Train: 69.57%, Valid: 69.16% Test: 69.38%\n",
      "Epoch: 42, Loss: 1.0398, Train: 69.75%, Valid: 69.47% Test: 69.67%\n",
      "Epoch: 43, Loss: 1.0340, Train: 70.04%, Valid: 69.66% Test: 69.83%\n",
      "Epoch: 44, Loss: 1.0323, Train: 70.34%, Valid: 69.84% Test: 69.94%\n",
      "Epoch: 45, Loss: 1.0257, Train: 70.45%, Valid: 69.99% Test: 70.00%\n",
      "Epoch: 46, Loss: 1.0274, Train: 70.34%, Valid: 69.96% Test: 69.98%\n",
      "Epoch: 47, Loss: 1.0219, Train: 70.23%, Valid: 69.77% Test: 69.86%\n",
      "Epoch: 48, Loss: 1.0192, Train: 70.25%, Valid: 69.85% Test: 69.89%\n",
      "Epoch: 49, Loss: 1.0139, Train: 70.52%, Valid: 70.09% Test: 70.05%\n",
      "Epoch: 50, Loss: 1.0124, Train: 70.86%, Valid: 70.28% Test: 69.92%\n",
      "Epoch: 51, Loss: 1.0104, Train: 71.12%, Valid: 70.48% Test: 69.85%\n",
      "Epoch: 52, Loss: 1.0064, Train: 71.27%, Valid: 70.61% Test: 69.68%\n",
      "Epoch: 53, Loss: 1.0031, Train: 71.50%, Valid: 70.65% Test: 69.76%\n",
      "Epoch: 54, Loss: 0.9999, Train: 71.61%, Valid: 70.78% Test: 69.97%\n",
      "Epoch: 55, Loss: 0.9997, Train: 71.75%, Valid: 70.89% Test: 69.97%\n",
      "Epoch: 56, Loss: 0.9949, Train: 71.81%, Valid: 70.72% Test: 69.49%\n",
      "Epoch: 57, Loss: 0.9942, Train: 71.80%, Valid: 70.68% Test: 69.45%\n",
      "Epoch: 58, Loss: 0.9917, Train: 71.89%, Valid: 70.84% Test: 69.81%\n",
      "Epoch: 59, Loss: 0.9880, Train: 71.84%, Valid: 70.82% Test: 70.23%\n",
      "Epoch: 60, Loss: 0.9874, Train: 71.89%, Valid: 70.88% Test: 70.27%\n",
      "Epoch: 61, Loss: 0.9820, Train: 71.99%, Valid: 70.86% Test: 70.08%\n",
      "Epoch: 62, Loss: 0.9827, Train: 72.08%, Valid: 70.73% Test: 69.36%\n",
      "Epoch: 63, Loss: 0.9809, Train: 72.19%, Valid: 70.79% Test: 69.57%\n",
      "Epoch: 64, Loss: 0.9773, Train: 72.19%, Valid: 70.83% Test: 69.74%\n",
      "Epoch: 65, Loss: 0.9770, Train: 72.32%, Valid: 71.11% Test: 70.06%\n",
      "Epoch: 66, Loss: 0.9725, Train: 72.43%, Valid: 71.07% Test: 69.85%\n",
      "Epoch: 67, Loss: 0.9737, Train: 72.46%, Valid: 71.13% Test: 69.75%\n",
      "Epoch: 68, Loss: 0.9691, Train: 72.42%, Valid: 71.15% Test: 69.84%\n",
      "Epoch: 69, Loss: 0.9678, Train: 72.43%, Valid: 71.33% Test: 70.41%\n",
      "Epoch: 70, Loss: 0.9678, Train: 72.50%, Valid: 71.39% Test: 70.78%\n",
      "Epoch: 71, Loss: 0.9639, Train: 72.69%, Valid: 71.29% Test: 69.87%\n",
      "Epoch: 72, Loss: 0.9604, Train: 72.52%, Valid: 70.60% Test: 68.73%\n",
      "Epoch: 73, Loss: 0.9563, Train: 72.57%, Valid: 70.83% Test: 69.21%\n",
      "Epoch: 74, Loss: 0.9567, Train: 72.69%, Valid: 71.33% Test: 70.15%\n",
      "Epoch: 75, Loss: 0.9545, Train: 72.66%, Valid: 71.33% Test: 70.56%\n",
      "Epoch: 76, Loss: 0.9509, Train: 72.78%, Valid: 71.14% Test: 69.99%\n",
      "Epoch: 77, Loss: 0.9499, Train: 72.91%, Valid: 70.86% Test: 69.21%\n",
      "Epoch: 78, Loss: 0.9513, Train: 72.93%, Valid: 70.85% Test: 69.08%\n",
      "Epoch: 79, Loss: 0.9481, Train: 72.92%, Valid: 70.91% Test: 69.41%\n",
      "Epoch: 80, Loss: 0.9478, Train: 73.01%, Valid: 71.42% Test: 70.31%\n",
      "Epoch: 81, Loss: 0.9435, Train: 73.00%, Valid: 71.38% Test: 70.34%\n",
      "Epoch: 82, Loss: 0.9434, Train: 72.99%, Valid: 70.86% Test: 69.34%\n",
      "Epoch: 83, Loss: 0.9417, Train: 72.98%, Valid: 70.97% Test: 69.48%\n",
      "Epoch: 84, Loss: 0.9411, Train: 73.06%, Valid: 71.44% Test: 70.43%\n",
      "Epoch: 85, Loss: 0.9370, Train: 73.05%, Valid: 71.33% Test: 70.24%\n",
      "Epoch: 86, Loss: 0.9382, Train: 72.87%, Valid: 70.91% Test: 69.42%\n",
      "Epoch: 87, Loss: 0.9358, Train: 73.09%, Valid: 70.80% Test: 69.10%\n",
      "Epoch: 88, Loss: 0.9327, Train: 73.18%, Valid: 70.79% Test: 68.87%\n",
      "Epoch: 89, Loss: 0.9320, Train: 73.06%, Valid: 70.59% Test: 68.62%\n",
      "Epoch: 90, Loss: 0.9293, Train: 73.36%, Valid: 71.24% Test: 69.43%\n",
      "Epoch: 91, Loss: 0.9263, Train: 73.51%, Valid: 71.55% Test: 70.26%\n",
      "Epoch: 92, Loss: 0.9276, Train: 73.40%, Valid: 71.40% Test: 70.06%\n",
      "Epoch: 93, Loss: 0.9259, Train: 73.27%, Valid: 70.89% Test: 69.29%\n",
      "Epoch: 94, Loss: 0.9223, Train: 73.20%, Valid: 70.51% Test: 68.55%\n",
      "Epoch: 95, Loss: 0.9230, Train: 73.49%, Valid: 71.51% Test: 70.24%\n",
      "Epoch: 96, Loss: 0.9183, Train: 73.68%, Valid: 71.74% Test: 70.43%\n",
      "Epoch: 97, Loss: 0.9208, Train: 73.72%, Valid: 71.52% Test: 70.02%\n",
      "Epoch: 98, Loss: 0.9186, Train: 73.77%, Valid: 71.74% Test: 70.45%\n",
      "Epoch: 99, Loss: 0.9170, Train: 73.73%, Valid: 71.79% Test: 71.05%\n",
      "Epoch: 100, Loss: 0.9160, Train: 73.75%, Valid: 71.81% Test: 70.71%\n"
     ]
    }
   ],
   "source": [
    "# 请不要改变 args\n",
    "# 使用 GPU 训练应该小于 10 分钟\n",
    "import copy\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # reset the parameters to initial random value\n",
    "  model.reset_parameters()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  loss_fn = F.nll_loss\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ba146-f025-4bbe-8da2-fd1c2ccc049a",
   "metadata": {},
   "source": [
    "### Question 5 ：你的**最佳模型**验证集和测试集精度如何？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885c987-2b43-411a-bb0d-9a8144c15532",
   "metadata": {},
   "source": [
    "运行下面的代码单元格，可以查看你最优模型的预测结果，  \n",
    "并将模型的预测保存到名为 `ogbn-arxiv_node.csv` 的文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6145cd0-730d-4e24-a84e-910065ba56b6",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Predictions\n",
      "Best model: Train: 73.75%, Valid: 71.81% Test: 70.71%\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n",
    "  train_acc, valid_acc, test_acc = best_result\n",
    "  print(f'Best model: '\n",
    "        f'Train: {100 * train_acc:.2f}%, '\n",
    "        f'Valid: {100 * valid_acc:.2f}% '\n",
    "        f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef8744-c54a-450c-825f-fafd252d736e",
   "metadata": {},
   "source": [
    "# 4） GNN：图性质预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f5853-5ae2-4375-8821-fc7078e58eba",
   "metadata": {},
   "source": [
    "在这一节中我们将创建一个为图性质预测的 GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240813b-9fdf-4de8-8f51-0612fc502664",
   "metadata": {},
   "source": [
    "## 加载并预处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb19ef2-dac5-450e-81aa-4c773a5e219f",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/hiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:00<00:00, 94095.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:05<00:00, 7479.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Device: cuda\n",
      "Task type: binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/ogb/graphproppred/dataset_pyg.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # 加载数据集\n",
    "  dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  print('Device: {}'.format(device))\n",
    "\n",
    "  split_idx = dataset.get_idx_split()\n",
    "\n",
    "  # 检查任务类型\n",
    "  print('Task type: {}'.format(dataset.task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b8d6f17-d624-49e8-b299-0c46462573dc",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# 将数据集划分加载到对应的 dataloader 中\n",
    "# 我们将在每批 32 个图上进行图分类任务的训练\n",
    "# 对训练集中的图顺序进行打乱\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "  valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "  test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a2c7ab3-20ab-4450-ab53-96ee2f07ef84",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  # Please do not change the args\n",
    "  args = {\n",
    "      'device': device,\n",
    "      'num_layers': 5,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.001,\n",
    "      'epochs': 30,\n",
    "  }\n",
    "  args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b82d0-68d0-4909-a83b-e6aecb15835c",
   "metadata": {},
   "source": [
    "## 图预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fc3c5-cff2-4371-96f7-ae20f775265d",
   "metadata": {},
   "source": [
    "图的 Mini-Batching（小批量处理）\n",
    "\n",
    "在正式进入模型之前，我们先介绍图数据的 mini-batching 概念。为了并行处理一小批图，  \n",
    "PyG 会将这些图组合成一个**不相连的大图**数据对象（`torch_geometric.data.Batch`）。\n",
    "\n",
    "`torch_geometric.data.Batch` 继承自之前介绍的 `torch_geometric.data.Data`，  \n",
    "并额外包含一个名为 `batch` 的属性。\n",
    "\n",
    "这个 `batch` 属性是一个向量，用来将每个节点映射到它在 mini-batch 中所属图的索引。例如：\n",
    "<code>batch = [0, ..., 0, 1, ..., 1, ..., n - 2, n - 1, ..., n - 1]<code>\n",
    "\n",
    "这个属性非常重要，它能帮助我们知道每个节点属于哪个图。  \n",
    "举个例子，它可以用来对每个图的节点嵌入进行平均，从而得到图级别的嵌入表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80d420-852d-42c4-9dbc-a5165b342943",
   "metadata": {},
   "source": [
    "### 补全"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de7abd",
   "metadata": {},
   "source": [
    "现在，我们已经具备了实现 GCN 图预测模型所需的所有工具！\n",
    "\n",
    "我们将复用现有的 GCN 模型来生成 **节点嵌入（node_embeddings）**，  \n",
    "然后对节点进行 **全局池化（Global Pooling）**，从而得到每个图的**图级别嵌入（graph level embeddings）**，  \n",
    "这些嵌入将用于预测每个图的属性。\n",
    "\n",
    "请记住，`batch` 属性对于在 mini-batch 中执行全局池化操作是很重要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4745e00-05a5-4208-bf76-2b27c4e01cd5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "\n",
    "### GCN 用于预测图属性\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # 加载分子图中原子的编码器\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "\n",
    "        # 节点嵌入模型\n",
    "        # 注意：输入维度和输出维度都设置为 hidden_dim\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
    "            hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## 注意：\n",
    "        ## 1. 将 self.pool 初始化为全局平均池化层（global mean pooling）\n",
    "        ##    更多信息请参考文档：\n",
    "        ##    https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # 输出层\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      self.gnn_node.reset_parameters()\n",
    "      self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        # TODO: 实现一个函数，输入是一批图（torch_geometric.data.Batch），\n",
    "        # 返回的是每个图的预测属性。\n",
    "        #\n",
    "        # 注意：由于我们预测的是图级别的属性，\n",
    "        x = self.node_encoder(batched_data.x)\n",
    "        node_embeddings = self.gnn_node(x, batched_data.edge_index)\n",
    "        graph_embeddings = self.pool(node_embeddings, batched_data.batch)\n",
    "        out = self.linear(graph_embeddings)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13b98918-c094-4e89-8114-1dd198e8f96c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    # TODO: 实现一个使用给定优化器和损失函数训练模型的函数。\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "      batch = batch.to(device)\n",
    "\n",
    "      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "          continue\n",
    "      else:\n",
    "        ## 在计算训练损失时忽略包含 nan 的目标（未标注样本）\n",
    "        is_labeled = batch.y == batch.y\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## 注意：\n",
    "        ## 1. 对优化器执行 zero grad（清除梯度）\n",
    "        ## 2. 将数据输入模型\n",
    "        ## 3. 使用 `is_labeled` 掩码过滤输出和标签\n",
    "        ## 4. 你可能需要将标签的类型转为 torch.float32\n",
    "        ## 5. 将输出和标签传入 loss_fn 计算损失\n",
    "        ## （大约 3 行代码）\n",
    "\n",
    "        #########################################\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        labeled_out = out[is_labeled]\n",
    "        labeled_y = batch.y[is_labeled].float()\n",
    "        loss = loss_fn(labeled_out, labeled_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e3ff2ed-7b6a-4679-80db-ec5ecbce5b85",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 用于分析的函数\n",
    "def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    if save_model_results:\n",
    "        print (\"Saving Model Predictions\")\n",
    "\n",
    "        # 创建一个包含两列的 pandas 数据框（DataFrame）\n",
    "        # y_pred | y_true\n",
    "        data = {}\n",
    "        data['y_pred'] = y_pred.reshape(-1)\n",
    "        data['y_true'] = y_true.reshape(-1)\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        # Save to csv\n",
    "        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n",
    "\n",
    "    return evaluator.eval(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a6ecd5a-233a-45aa-8662-452e948b91cc",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model = GCN_Graph(args['hidden_dim'],\n",
    "              dataset.num_tasks, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "  evaluator = Evaluator(name='ogbg-molhiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee01caa2-e31a-46b4-b8a8-50f65b1913cd",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:20<00:00, 50.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 111.11it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 85.83it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 85.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.9359, Train: 70.35%, Valid: 66.61% Test: 65.21%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 71.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.99it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 106.99it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 111.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 0.0576, Train: 74.60%, Valid: 71.81% Test: 71.85%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 68.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 110.67it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 109.79it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Loss: 0.0257, Train: 77.21%, Valid: 74.34% Test: 70.04%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 63.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 126.58it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 100.88it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 98.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Loss: 1.2354, Train: 75.92%, Valid: 75.88% Test: 72.54%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 63.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 124.64it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 101.89it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 98.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Loss: 0.5099, Train: 76.43%, Valid: 75.21% Test: 71.87%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 64.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 109.63it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.98it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:00<00:00, -2823.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Loss: 0.0197, Train: 78.51%, Valid: 75.53% Test: 71.38%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 63.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 108.96it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 105.65it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Loss: 0.0310, Train: 77.97%, Valid: 75.25% Test: 72.04%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 71.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.85it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.80it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 101.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Loss: 0.0315, Train: 78.57%, Valid: 75.33% Test: 72.96%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 68.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.06it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 98.76it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Loss: 0.0460, Train: 78.23%, Valid: 76.40% Test: 74.69%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 69.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 109.18it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.00it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 111.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.0856, Train: 79.14%, Valid: 74.50% Test: 74.22%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 63.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 125.27it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 105.41it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 106.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.0274, Train: 78.69%, Valid: 76.07% Test: 69.55%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 62.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 126.99it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.87it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 105.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.0243, Train: 80.08%, Valid: 73.80% Test: 74.42%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 65.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 103.85it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:00<00:00, -1005.36it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.0521, Train: 81.35%, Valid: 76.51% Test: 73.07%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 65.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 109.75it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 113.20it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 112.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.0282, Train: 81.23%, Valid: 74.40% Test: 73.22%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 63.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:13<00:00, 76.38it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 71.60it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 78.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.0283, Train: 80.68%, Valid: 76.71% Test: 72.62%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:18<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 103.45it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 98.43it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 109.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.0506, Train: 80.66%, Valid: 75.73% Test: 72.06%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 70.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:13<00:00, 75.28it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 81.86it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 83.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.0634, Train: 81.16%, Valid: 76.88% Test: 74.58%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:19<00:00, 54.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:13<00:00, 77.98it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:00<00:00, 448.10it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 75.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.0359, Train: 82.18%, Valid: 76.35% Test: 72.52%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:18<00:00, 56.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 105.14it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 97.76it/s] \n",
      "Iteration: 100%|██████████| 129/129 [00:00<00:00, -18095.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.0348, Train: 82.13%, Valid: 75.62% Test: 74.36%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 62.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 105.76it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 110.57it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 110.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.0232, Train: 82.21%, Valid: 75.83% Test: 71.59%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 71.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 110.54it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 111.02it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 110.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.0334, Train: 82.49%, Valid: 78.07% Test: 73.92%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.17it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.04it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.0305, Train: 82.92%, Valid: 75.59% Test: 73.51%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 70.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.86it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 101.72it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 110.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.0509, Train: 82.36%, Valid: 77.03% Test: 74.67%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 64.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 126.15it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 106.61it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 106.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.0301, Train: 82.55%, Valid: 76.97% Test: 75.07%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:16<00:00, 62.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:08<00:00, 122.90it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.05it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 112.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.0196, Train: 83.17%, Valid: 76.94% Test: 73.73%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 65.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.92it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:00<00:00, -1666.42it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.0195, Train: 83.28%, Valid: 74.85% Test: 74.43%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 64.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 107.70it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.53it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 92.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.0211, Train: 82.98%, Valid: 80.02% Test: 74.91%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:15<00:00, 68.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:09<00:00, 106.91it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 99.97it/s] \n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.0268, Train: 83.60%, Valid: 79.03% Test: 75.17%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 69.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:10<00:00, 102.05it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 107.31it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 108.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.0379, Train: 83.72%, Valid: 78.19% Test: 74.74%\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:14<00:00, 68.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:10<00:00, 101.94it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 111.65it/s]\n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 109.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.0251, Train: 83.11%, Valid: 78.58% Test: 74.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  model.reset_parameters()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    train_result = eval(model, device, train_loader, evaluator)\n",
    "    val_result = eval(model, device, valid_loader, evaluator)\n",
    "    test_result = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a329e-3860-44a7-bbb1-30d4dbdc63ee",
   "metadata": {},
   "source": [
    "### Quesion 6： 你的最佳模型的验证/测试 ROC-AUC 分数多少？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eedb6e-0e2d-4d37-aab3-0cbe3c3f77eb",
   "metadata": {},
   "source": [
    "运行下方的代码单元格，以查看你最优模型的预测结果，  \n",
    "并将预测分别保存为两个文件：`ogbg-molhiv_graph_valid.csv` 和 `ogbg-molhiv_graph_test.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfa1ed98-c3b5-4a0d-b76d-dfd7961e0e71",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1029/1029 [00:19<00:00, 53.81it/s] \n",
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 90.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 129/129 [00:01<00:00, 97.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Predictions\n",
      "Best model: Train: 82.98%, Valid: 80.02% Test: 74.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "  train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "  valid_auroc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n",
    "  test_auroc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n",
    "\n",
    "  print(f'Best model: '\n",
    "      f'Train: {100 * train_auroc:.2f}%, '\n",
    "      f'Valid: {100 * valid_auroc:.2f}% '\n",
    "      f'Test: {100 * test_auroc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c168ff-267c-4846-b384-4f1a0f76a278",
   "metadata": {},
   "source": [
    "### Question 7（选做）：在PyG中测试另外两种 global pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac3fc3-0ad0-41cd-9b0d-7016bdac7876",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "############# Your code here ############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
